import streamlit as st
import pandas as pd
import io
import re
import smtplib
import gspread
from datetime import date
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders

# ==========================================
# ğŸ” 1. å®‰å…¨è¨­å®šèˆ‡ç’°å¢ƒé…ç½®
# ==========================================
try:
    MY_EMAIL = st.secrets["email"]["user"]
    MY_PASSWORD = st.secrets["email"]["password"]
    GCP_CREDS = st.secrets["gcp_service_account"]
except Exception as e:
    st.error("âŒ æ‰¾ä¸åˆ° Secrets è¨­å®šï¼è«‹åœ¨è¨­å®šå€é…ç½® [email] èˆ‡ [gcp_service_account]ã€‚")
    st.stop()

TO_EMAIL = MY_EMAIL
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 587
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1HaFu5PZkFDUg7WZGV9khyQ0itdGXhXUakP4_BClFTUg/edit"

st.set_page_config(page_title="äº¤é€šäº‹æ•…çµ±è¨ˆç³»çµ±", layout="wide", page_icon="ğŸš‘")

# ==========================================
# ğŸ› ï¸ 2. å·¥å…·å‡½å¼ (å¿…é ˆæ”¾åœ¨æœ€ä¸Šæ–¹)
# ==========================================

def parse_raw(f):
    """è§£æ CSV æˆ– Excel æª”æ¡ˆ"""
    try:
        f.seek(0)
        return pd.read_csv(f, header=None)
    except:
        f.seek(0)
        return pd.read_excel(f, header=None)

def clean_data(df_raw):
    """æ¸…æ´—å ±è¡¨åŸå§‹è³‡æ–™ï¼Œæå–é—œéµæ¬„ä½"""
    df_raw[0] = df_raw[0].astype(str)
    # ç¯©é¸åŒ…å«ã€Œæ‰€ã€æˆ–ã€Œåˆè¨ˆã€çš„è¡Œ
    df_data = df_raw[df_raw[0].str.contains("æ‰€|ç¸½è¨ˆ|åˆè¨ˆ", na=False)].copy()
    cols = {0: "Station", 5: "A1_Deaths", 9: "A2_Injuries"}
    df_data = df_data.rename(columns=cols)
    
    # è½‰æ›æ•¸å€¼ä¸¦è™•ç†åƒåˆ†ä½é€—è™Ÿ
    for c in [5, 9]:
        col_name = cols[c]
        df_data[col_name] = pd.to_numeric(df_data[col_name].astype(str).str.replace(",", ""), errors='coerce').fillna(0)
    
    # çµ±ä¸€å–®ä½åç¨±
    df_data['Station_Short'] = df_data['Station'].str.replace('æ´¾å‡ºæ‰€', 'æ‰€').str.replace('ç¸½è¨ˆ', 'åˆè¨ˆ')
    return df_data

def format_html_header(text):
    """HTML é¡¯ç¤ºç´…å­—æ•¸å­—"""
    text = str(text)
    tokens = re.split(r'([0-9\(\)\/\-\.\%]+)', text)
    html_str = "".join([f'<span style="color: red;">{t}</span>' if re.match(r'^[0-9\(\)\/\-\.\%]+$', t) else f'<span>{t}</span>' for t in tokens])
    return html_str

def render_styled_table(df, title):
    """åœ¨ Streamlit æ¸²æŸ“ç¾åŒ–è¡¨æ ¼"""
    st.subheader(title)
    style = "<style>table.acc_table {width:100%; border-collapse:collapse;} th, td {border:1px solid black; padding:8px; text-align:center;}</style>"
    html = f"{style}<table class='acc_table'><thead><tr>"
    for col in df.columns: html += f"<th>{format_html_header(col)}</th>"
    html += "</tr></thead><tbody>"
    for _, row in df.iterrows():
        html += "<tr>"
        for col_name, val in row.items():
            color = "red" if ("æ¯”è¼ƒ" in col_name or "å¢æ¸›" in col_name) and str(val) != "0.00%" and "-" not in str(val) and str(val) != "0" else "black"
            html += f'<td style="color: {color};">{val}</td>'
        html += "</tr>"
    st.markdown(html + "</tbody></table>", unsafe_allow_html=True)

# ==========================================
# ğŸ“Š 3. æ ¸å¿ƒè¨ˆç®—å‡½å¼ (åƒæ•¸å‚³éé¿å… NameError)
# ==========================================

def build_a1_table(wk_df, cur_df, lst_df, stations):
    col = 'A1_Deaths'
    m = pd.merge(wk_df[['Station_Short', col]], cur_df[['Station_Short', col]], on='Station_Short', suffixes=('_wk', '_cur'))
    m = pd.merge(m, lst_df[['Station_Short', col]], on='Station_Short').rename(columns={col: col+'_lst'})
    
    m = m[m['Station_Short'].isin(stations)].copy()
    total = m.select_dtypes(include='number').sum().to_dict()
    total['Station_Short'] = 'åˆè¨ˆ'
    m = pd.concat([pd.DataFrame([total]), m], ignore_index=True)
    
    m['Diff'] = m[col+'_cur'] - m[col+'_lst']
    # 5 æ¬„æ’åˆ—
    m = m[['Station_Short', col+'_wk', col+'_cur', col+'_lst', 'Diff']]
    return m

def build_a2_table(wk_df, cur_df, lst_df, stations):
    col = 'A2_Injuries'
    m = pd.merge(wk_df[['Station_Short', col]], cur_df[['Station_Short', col]], on='Station_Short', suffixes=('_wk', '_cur'))
    m = pd.merge(m, lst_df[['Station_Short', col]], on='Station_Short').rename(columns={col: col+'_lst'})
    
    m = m[m['Station_Short'].isin(stations)].copy()
    total = m.select_dtypes(include='number').sum().to_dict()
    total['Station_Short'] = 'åˆè¨ˆ'
    m = pd.concat([pd.DataFrame([total]), m], ignore_index=True)
    
    m['Diff'] = m[col+'_cur'] - m[col+'_lst']
    m['Pct'] = m.apply(lambda x: f"{(x['Diff']/x[col+'_lst']):.2%}" if x[col+'_lst'] != 0 else "0.00%", axis=1)
    
    # 7 æ¬„æ’åˆ—ï¼Œç²¾æº–æ’å…¥ 'Prev' æ–¼ç´¢å¼• 2 (ç¬¬3æ¬„)
    m.insert(2, 'Prev', '-')
    m = m[['Station_Short', col+'_wk', 'Prev', col+'_cur', col+'_lst', 'Diff', 'Pct']]
    return m

# ==========================================
# ğŸš€ 4. Streamlit ä¸»æµç¨‹
# ==========================================

st.title("ğŸš‘ äº¤é€šäº‹æ•…çµ±è¨ˆ (æ ¼å¼å°é½Šä¿®æ­£ç‰ˆ)")
uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ 3 å€‹å ±è¡¨æª”æ¡ˆ (æœ¬æœŸã€æœ¬å¹´ç´¯è¨ˆã€å»å¹´åŒæœŸç´¯è¨ˆ)", accept_multiple_files=True)

if uploaded_files and len(uploaded_files) == 3:
    with st.spinner("âš¡ æ•¸æ“šåˆ†æä¸­..."):
        try:
            files_meta = []
            for f in uploaded_files:
                df_raw = parse_raw(f)
                # åµæ¸¬æ—¥æœŸ (æ°‘åœ‹å¹´æ ¼å¼)
                dates = re.findall(r'(\d{3})[./](\d{1,2})[./](\d{1,2})', str(df_raw.iloc[:5, :5].values))
                if len(dates) >= 2:
                    d_str = f"{int(dates[0][1]):02d}{int(dates[0][2]):02d}-{int(dates[1][1]):02d}{int(dates[1][2]):02d}"
                    files_meta.append({
                        'df': clean_data(df_raw), 
                        'year': int(dates[1][0]), 
                        'date_range': d_str, 
                        'is_cumu': (int(dates[0][1]) == 1)
                    })

            if len(files_meta) < 3:
                st.error("âŒ ç„¡æ³•è¾¨è­˜æ—¥æœŸï¼Œè«‹ç¢ºèªæª”æ¡ˆæ¨™é¡ŒåŒ…å«æ°‘åœ‹å¹´æœˆæ—¥å€é–“ã€‚")
                st.stop()

            # åˆ†é…è®Šæ•¸
            files_meta.sort(key=lambda x: x['year'], reverse=True)
            cur_year = files_meta[0]['year']
            
            df_wk = [f for f in files_meta if f['year'] == cur_year and not f['is_cumu']][0]
            df_cur = [f for f in files_meta if f['year'] == cur_year and f['is_cumu']][0]
            df_lst = [f for f in files_meta if f['year'] < cur_year][0]

            # æŒ‡å®šæ´¾å‡ºæ‰€
            stations = ['è–äº­æ‰€', 'é¾æ½­æ‰€', 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ‰€', 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ‰€']

            # ç”¢ç”Ÿçµæœ DataFrame (æ­¤è™•å·²è§£æ±º NameError)
            a1_res = build_a1_table(df_wk['df'], df_cur['df'], df_lst['df'], stations)
            a1_res.columns = ['çµ±è¨ˆæœŸé–“', f'æœ¬æœŸ({df_wk["date_range"]})', f'æœ¬å¹´ç´¯è¨ˆ({df_cur["date_range"]})', f'å»å¹´ç´¯è¨ˆ({df_lst["date_range"]})', 'æ¯”è¼ƒ']

            a2_res = build_a2_table(df_wk['df'], df_cur['df'], df_lst['df'], stations)
            a2_res.columns = ['çµ±è¨ˆæœŸé–“', f'æœ¬æœŸ({df_wk["date_range"]})', 'å‰æœŸ', f'æœ¬å¹´ç´¯è¨ˆ({df_cur["date_range"]})', f'å»å¹´ç´¯è¨ˆ({df_lst["date_range"]})', 'æ¯”è¼ƒ', 'å¢æ¸›æ¯”ä¾‹']

            # é¡¯ç¤ºè¡¨æ ¼
            col1, col2 = st.columns(2)
            with col1: render_styled_table(a1_res, "ğŸ“Š A1 æ­»äº¡äººæ•¸")
            with col2: render_styled_table(a2_res, "ğŸ“Š A2 å—å‚·äººæ•¸")

            st.success("âœ… æ•¸æ“šå°é½Šå®Œæˆï¼æ•¸å€¼å·²æŒ‰ç…§ã€Œå–®ä½ > æœ¬æœŸ > å‰æœŸ > ç´¯è¨ˆã€é †åºæ’åˆ—ã€‚")

        except Exception as e:
            st.error(f"åˆ†æç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
