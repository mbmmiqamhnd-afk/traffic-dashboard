import streamlit as st
import pandas as pd
import re
import io
import smtplib
import gspread
import calendar
import numpy as np
import traceback
import csv
from datetime import date, datetime
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from email.header import Header

# --- åˆå§‹åŒ–é…ç½® ---
st.set_page_config(page_title="äº¤é€šäº‹æ•…çµ±è¨ˆ", layout="wide", page_icon="ğŸ’¥")
st.title("ğŸ’¥ äº¤é€šäº‹æ•…çµ±è¨ˆ (v86 ç¸®æ’ä¿®æ­£ç‰ˆ)")

# ==========================================
# 0. è¨­å®šå€
# ==========================================
GOOGLE_SHEET_URL = "[https://docs.google.com/spreadsheets/d/1HaFu5PZkFDUg7WZGV9khyQ0itdGXhXUakP4_BClFTUg/edit](https://docs.google.com/spreadsheets/d/1HaFu5PZkFDUg7WZGV9khyQ0itdGXhXUakP4_BClFTUg/edit)" 

# å–®ä½å°ç…§è¡¨
UNIT_MAP = {
    'è–äº­æ´¾å‡ºæ‰€': 'è–äº­æ‰€', 'é¾æ½­æ´¾å‡ºæ‰€': 'é¾æ½­æ‰€', 'ä¸­èˆˆæ´¾å‡ºæ‰€': 'ä¸­èˆˆæ‰€', 
    'çŸ³é–€æ´¾å‡ºæ‰€': 'çŸ³é–€æ‰€', 'é«˜å¹³æ´¾å‡ºæ‰€': 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ´¾å‡ºæ‰€': 'ä¸‰å’Œæ‰€', 
    'è­¦å‚™éšŠ': 'è­¦å‚™éšŠ', 'é¾æ½­äº¤é€šåˆ†éšŠ': 'äº¤é€šåˆ†éšŠ', 'äº¤é€šä¸­éšŠ': 'äº¤é€šåˆ†éšŠ',
    'ç§‘æŠ€åŸ·æ³•': 'ç§‘æŠ€åŸ·æ³•', 'äº¤é€šçµ„': 'äº¤é€šçµ„'
}

# å ±è¡¨é¡¯ç¤ºé †åº
UNIT_ORDER = ['äº¤é€šçµ„', 'è–äº­æ‰€', 'é¾æ½­æ‰€', 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ‰€', 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ', 'äº¤é€šåˆ†éšŠ']

# ==========================================
# 1. Google è©¦ç®—è¡¨ API è¼”åŠ©å‡½å¼
# ==========================================
def get_merge_request(ws_id, start_col, end_col):
    """ç”¢ç”Ÿåˆä½µå„²å­˜æ ¼çš„ API è«‹æ±‚"""
    return {
        "mergeCells": {
            "range": {
                "sheetId": ws_id, 
                "startRowIndex": 1, "endRowIndex": 2, 
                "startColumnIndex": start_col, "endColumnIndex": end_col
            }, 
            "mergeType": "MERGE_ALL"
        }
    }

def get_center_align_request(ws_id, start_col, end_col):
    """ç”¢ç”Ÿç½®ä¸­å°é½Šçš„ API è«‹æ±‚"""
    return {
        "repeatCell": {
            "range": {
                "sheetId": ws_id, 
                "startRowIndex": 1, "endRowIndex": 2, 
                "startColumnIndex": start_col, "endColumnIndex": end_col
            }, 
            "cell": {"userEnteredFormat": {"horizontalAlignment": "CENTER"}}, 
            "fields": "userEnteredFormat.horizontalAlignment"
        }
    }

def get_header_red_req(ws_id, row_idx, col_idx, text):
    """ç”¢ç”Ÿç´…å­—æ¨™é¡Œçš„ API è«‹æ±‚"""
    red_chars = set("0123456789~().%")
    runs = []
    text_str = str(text)
    last_is_red = None
    for i, char in enumerate(text_str):
        is_red = char in red_chars
        if is_red != last_is_red:
            color = {"red": 1.0, "green": 0, "blue": 0} if is_red else {"red": 0, "green": 0, "blue": 0}
            runs.append({"startIndex": i, "format": {"foregroundColor": color, "bold": is_red}})
            last_is_red = is_red
    return {
        "updateCells": {
            "rows": [{"values": [{"userEnteredValue": {"stringValue": text_str}, "textFormatRuns": runs}]}], 
            "fields": "userEnteredValue,textFormatRuns", 
            "range": {
                "sheetId": ws_id, 
                "startRowIndex": row_idx-1, "endRowIndex": row_idx, 
                "startColumnIndex": col_idx-1, "endColumnIndex": col_idx
            }
        }
    }

# ==========================================
# 2. æ ¸å¿ƒè§£æå¼•æ“ (é‡å°æ´¾å‡ºæ‰€ CSV çµæ§‹)
# ==========================================
def clean_int(val):
    """å°‡ CSV ä¸­çš„ç©ºå€¼ã€é€—è™Ÿè½‰ç‚ºæ•´æ•¸"""
    try:
        if pd.isna(val) or str(val).strip() in ['â€”', '', '-', 'nan', 'NaN']: return 0
        s = str(val).replace(',', '').strip()
        return int(float(s))
    except: return 0

def parse_police_station_csv_v86(file_obj):
    counts = {} 
    date_range_str = "0000~0000"
    
    try:
        file_obj.seek(0)
        content_lines = []
        try:
            content_str = file_obj.read().decode('utf-8')
            content_lines = content_str.splitlines()
        except:
            file_obj.seek(0)
            content_str = file_obj.read().decode('big5', errors='ignore')
            content_lines = content_str.splitlines()

        # æŠ“å–çµ±è¨ˆæ—¥æœŸ
        for line in content_lines[:8]:
            m = re.search(r'çµ±è¨ˆæ—¥æœŸ[ï¼š:]\s*(\d+)/(\d+)/(\d+)\s*è‡³\s*(\d+)/(\d+)/(\d+)', line)
            if m:
                s_m, s_d = m.group(2), m.group(3)
                e_m, e_d = m.group(5), m.group(6)
                date_range_str = f"{s_m}{s_d}~{e_m}{e_d}"
                break
        
        # å°‹æ‰¾æ¨™é¡Œåˆ—
        header_row_idx = -1
        for i, line in enumerate(content_lines):
            if "A 1 é¡" in line and "A 2 é¡" in line:
                header_row_idx = i
                break
        
        if header_row_idx != -1:
            try:
                df = pd.read_csv(io.StringIO("\n".join(content_lines)), skiprows=header_row_idx, header=None)
                
                # é–å®šæ¬„ä½åº§æ¨™
                idx_unit = 0
                idx_a1 = 4
                idx_a2 = 7
                idx_a3 = 10
                
                for r in range(2, len(df)):
                    row = df.iloc[r]
                    if len(row) <= 10: continue
                    
                    unit_raw = str(row[idx_unit]).strip()
                    target_unit = None
                    
                    if "ç¸½è¨ˆ" in unit_raw or "åˆè¨ˆ" in unit_raw: 
                        target_unit = "åˆè¨ˆ"
                    else:
                        for full, short in UNIT_MAP.items():
                            if full in unit_raw or short in unit_raw:
                                target_unit = short; break
                    
                    if target_unit:
                        if target_unit in counts: continue
                        v_a1 = clean_int(row[idx_a1])
                        v_a2 = clean_int(row[idx_a2])
                        v_a3 = clean_int(row[idx_a3])
                        counts[target_unit] = [v_a1, v_a2, v_a3]
            except Exception as e:
                print(f"DataFrame error: {e}")

    except Exception as e:
        print(f"File error: {e}")

    return counts, date_range_str

# ==========================================
# 3. ç•«é¢é¡¯ç¤ºèˆ‡è‡ªå‹•åŒ–é‚è¼¯
# ==========================================
files = st.file_uploader("è«‹ä¸Šå‚³ 3 å€‹æ´¾å‡ºæ‰€æ‰€è½„æ¡ˆä»¶çµ±è¨ˆè¡¨ (CSV)", accept_multiple_files=True)

if files and len(files) >= 3:
    try:
        # 1. è§£ææª”æ¡ˆ
        parsed_data = []
        for f in files:
            d, d_str = parse_police_station_csv_v86(f)
            parsed_data.append({"file": f, "data": d, "date": d_str, "name": f.name})
        
        # 2. æª”æ¡ˆåˆ†é¡
        f_wk, f_yt, f_ly = None, None, None
        
        for item in parsed_data:
            nm = item['name']
            if "(2)" in nm: f_ly = item
            elif "(1)" in nm: f_yt = item
            else: f_wk = item
            
        if not f_wk or not f_yt or not f_ly:
            st.warning("âš ï¸ æª”åç„¡æ³•è­˜åˆ¥ï¼Œä¾åºæ’åˆ—ã€‚")
            f_wk = parsed_data[0]; f_yt = parsed_data[1]; f_ly = parsed_data[2]

        d_wk, title_wk = f_wk['data'], f"æœ¬æœŸ({f_wk['date']})"
        d_yt, title_yt = f_yt['data'], f"æœ¬å¹´ç´¯è¨ˆ({f_yt['date']})"
        d_ly, title_ly = f_ly['data'], f"å»å¹´ç´¯è¨ˆ({f_ly['date']})"

        # HTML Header
        def red_h(t): return "".join([f"<span style='color:red; font-weight:bold;'>{c}</span>" if c in "0123456789~().%" else c for c in t])
        
        html_header = f"""
        <thead>
            <tr>
                <th>çµ±è¨ˆæœŸé–“</th>
                <th colspan='3' style='text-align:center;'>{red_h(title_wk)}</th>
                <th colspan='3' style='text-align:center;'>{red_h(title_yt)}</th>
                <th colspan='3' style='text-align:center;'>{red_h(title_ly)}</th>
                <th>æ¯”è¼ƒ</th>
            </tr>
            <tr>
                <th>å–®ä½</th>
                <th>A1</th><th>A2</th><th>A3</th>
                <th>A1</th><th>A2</th><th>A3</th>
                <th>A1</th><th>A2</th><th>A3</th>
                <th>å¢æ¸›</th>
            </tr>
        </thead>
        """

        # 3. æ•¸æ“šçµ„è£
        rows = []
        for u in UNIT_ORDER:
            wk = d_wk.get(u, [0, 0, 0])
            yt = d_yt.get(u, [0, 0, 0])
            ly = d_ly.get(u, [0, 0, 0])
            diff = sum(yt) - sum(ly)
            
            rows.append([
                u, 
                wk[0], wk[1], wk[2], 
                yt[0], yt[1], yt[2], 
                ly[0], ly[1], ly[2], 
                diff
            ])
            
        # åˆè¨ˆåˆ—
        total_row = ["åˆè¨ˆ"]
        for i in range(1, 11):
            col_sum = sum(r[i] for r in rows)
            total_row.append(col_sum)
            
        all_rows = [total_row] + rows
        
        st.success(f"âœ… è§£ææˆåŠŸï¼æœ¬æœŸæª”å: {f_wk['name']}")
        
        table_body = "".join([f"<tr>{''.join([f'<td>{x}</td>' for x in r])}</tr>" for r in all_rows])
        st.write(f"<table style='text-align:center; width:100%; border-collapse:collapse;' border='1'>{html_header}<tbody>{table_body}</tbody></table>", unsafe_allow_html=True)
        
        # 4. è‡ªå‹•å¯«å…¥
        file_hash = "".join([f.name + str(f.size) for f in files])
        
        if st.session_state.get("v86_done") != file_hash:
            with st.status("ğŸš€ æ­£åœ¨è‡ªå‹•å¯«å…¥é›²ç«¯...", expanded=True) as s:
                try:
                    gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
                    sh = gc.open_by_url(GOOGLE_SHEET_URL); ws = sh.get_worksheet(0)
                    
                    clean_payload = [
                        ["çµ±è¨ˆæœŸé–“", title_wk, "", "", title_yt, "", "", title_ly, "", "", "æ¯”è¼ƒ"],
                        ["å–®ä½", "A1", "A2", "A3", "A1", "A2", "A3", "A1", "A2", "A3", "å¢æ¸›"]
                    ]
                    
                    for r in all_rows:
                        clean_row = []
                        for cell in r:
                            if isinstance(cell, (int, float, np.integer)): clean_row.append(int(cell))
                            else: clean_row.append(str(cell))
                        clean_payload.append(clean_row)
                    
                    ws.update(range_name='A2', values=clean_payload)
                    
                    reqs = []
                    for s_col in [1, 4, 7]:
                         reqs.append(get_merge_request(ws.id, s_col, s_col+3))
                         reqs.append(get_center_align_request(ws.id, s_col, s_col+3))
                    
                    reqs.append(get_header_red_req(ws.id, 2, 2, title_wk))
                    reqs.append(get_header_red_req(ws.id, 2, 5, title_yt))
                    reqs.append(get_header_red_req(ws.id, 2, 8, title_ly))

                    sh.batch_update({"requests": reqs})
                    
                    st.session_state["v86_done"] = file_hash
                    s.update(label="âœ… æ•¸æ“šå·²è‡ªå‹•å¯«å…¥ Google Sheetsï¼", state="complete")
                    st.balloons()

                except Exception as e:
                    s.update(label="âŒ å¯«å…¥å¤±æ•—", state="error")
                    st.error(f"å¯«å…¥éŒ¯èª¤è©³æƒ…: {e}")
                    st.code(traceback.format_exc())

    except Exception as e:
        st.error(f"å…¨åŸŸéŒ¯èª¤: {e}")
        st.code(traceback.format_exc())
