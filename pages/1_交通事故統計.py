import streamlit as st
import pandas as pd
import io
import re
from datetime import datetime

# è¨­å®šé é¢é…ç½®
st.set_page_config(page_title="äº¤é€šäº‹æ•…çµ±è¨ˆè‡ªå‹•åŒ–", page_icon="ğŸš“", layout="wide")

def main():
    st.title("ğŸš“ äº¤é€šäº‹æ•…çµ±è¨ˆè‡ªå‹•åŒ–å·¥å…·")
    st.markdown("è«‹ä¸Šå‚³ **æœ¬é€±**ã€**ä»Šå¹´ç´¯è¨ˆ**ã€**å»å¹´ç´¯è¨ˆ** ä¸‰ä»½å ±è¡¨ï¼ˆæ”¯æ´ `.csv` æˆ– `.xlsx`ï¼‰ï¼Œç³»çµ±å°‡è‡ªå‹•è¾¨è­˜ä¸¦ç”¢å‡ºå ±è¡¨ã€‚")

    # 1. æª”æ¡ˆä¸Šå‚³å€ (å–ä»£ google.colab.files)
    uploaded_files = st.file_uploader("è«‹ä¸€æ¬¡é¸å–ä¸‰å€‹æª”æ¡ˆ", accept_multiple_files=True, type=['csv', 'xlsx'])

    if len(uploaded_files) == 3:
        if st.button("é–‹å§‹åˆ†æ"):
            with st.spinner('æ­£åœ¨è§£ææª”æ¡ˆèˆ‡è¨ˆç®—æ•¸æ“š...'):
                try:
                    process_files(uploaded_files)
                except Exception as e:
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    elif len(uploaded_files) > 0 and len(uploaded_files) != 3:
        st.warning(f"ç›®å‰å·²ä¸Šå‚³ {len(uploaded_files)} å€‹æª”æ¡ˆï¼Œè«‹ç¢ºä¿å‰›å¥½ä¸Šå‚³ 3 å€‹æª”æ¡ˆã€‚")

def parse_police_stats_raw(file_obj):
    """è®€å–æª”æ¡ˆä¸¦å›å‚³ DataFrame"""
    try:
        # Streamlit çš„ UploadedFile å¯ä»¥ç›´æ¥è®€å–
        df_raw = pd.read_csv(file_obj, header=None)
    except:
        file_obj.seek(0)
        df_raw = pd.read_excel(file_obj, header=None)
    return df_raw

def process_files(uploaded_files):
    # --- 2. æ™ºæ…§è¾¨è­˜æª”æ¡ˆèº«åˆ† ---
    file_data_map = []
    
    for file_obj in uploaded_files:
        # é‡ç½®æŒ‡é‡ä»¥é˜²è®€å–éŒ¯èª¤
        file_obj.seek(0)
        df = parse_police_stats_raw(file_obj)
        
        try:
            # æŠ“å–æ—¥æœŸå­—ä¸²
            date_str = df.iloc[1, 0].replace("çµ±è¨ˆæ—¥æœŸï¼š", "").strip()
            dates = re.findall(r'(\d{3})/(\d{2})/(\d{2})', date_str)
            
            if not dates:
                st.warning(f"ç„¡æ³•è­˜åˆ¥æ—¥æœŸï¼š{file_obj.name}")
                continue
                
            start_y, start_m, start_d = map(int, dates[0])
            end_y, end_m, end_d = map(int, dates[1])
            
            # åˆ¤æ–·é‚è¼¯
            month_diff = (end_y - start_y) * 12 + (end_m - start_m)
            
            if month_diff == 0 and (end_d - start_d) < 20:
                category = 'weekly'
            else:
                category = f'cumulative_{start_y}'
            
            file_data_map.append({
                'df': df,
                'date_str': date_str,
                'category': category,
                'year': start_y
            })
        except Exception as e:
            st.error(f"æª”æ¡ˆè§£æå¤±æ•— {file_obj.name}: {e}")
            return

    # åˆ†é…è§’è‰²
    df_wk, df_cur, df_lst = None, None, None
    d_wk, d_cur, d_lst = "", "", ""

    # æ‰¾å‡º Weekly
    for data in file_data_map:
        if data['category'] == 'weekly':
            df_wk = data['df']
            d_wk = data['date_str']
            break
            
    # æ‰¾å‡º Current å’Œ Last (æ¯”è¼ƒå¹´ä»½)
    cumulative_files = [d for d in file_data_map if 'cumulative' in d['category']]
    if len(cumulative_files) >= 2:
        cumulative_files.sort(key=lambda x: x['year'], reverse=True)
        df_cur, d_cur = cumulative_files[0]['df'], cumulative_files[0]['date_str']
        df_lst, d_lst = cumulative_files[1]['df'], cumulative_files[1]['date_str']
    
    if df_wk is None or df_cur is None or df_lst is None:
        st.error("âŒ è‡ªå‹•è¾¨è­˜å¤±æ•—ï¼Œç„¡æ³•å€åˆ†æœ¬é€±ã€ä»Šå¹´èˆ‡å»å¹´æª”æ¡ˆï¼Œè«‹æª¢æŸ¥æª”æ¡ˆå…§å®¹ã€‚")
        return

    st.success(f"âœ… æˆåŠŸè¾¨è­˜ï¼š\n- **æœ¬æœŸ**: {d_wk}\n- **ä»Šå¹´**: {d_cur}\n- **å»å¹´**: {d_lst}")

    # --- 3. è³‡æ–™æ¸…ç†èˆ‡è¨ˆç®— ---
    df_wk_clean = process_data(df_wk)
    df_cur_clean = process_data(df_cur)
    df_lst_clean = process_data(df_lst)

    # æº–å‚™æ¨™é¡Œæ—¥æœŸ
    h_wk = format_date(d_wk)
    h_cur = format_date(d_cur)
    h_lst = format_date(d_lst)

    # --- åˆä½µ A1 ---
    a1_wk = df_wk_clean[['Station_Short', 'A1_Deaths']].rename(columns={'A1_Deaths': 'wk'})
    a1_cur = df_cur_clean[['Station_Short', 'A1_Deaths']].rename(columns={'A1_Deaths': 'cur'})
    a1_lst = df_lst_clean[['Station_Short', 'A1_Deaths']].rename(columns={'A1_Deaths': 'last'})
    
    m_a1 = pd.merge(a1_wk, a1_cur, on='Station_Short', how='outer')
    m_a1 = pd.merge(m_a1, a1_lst, on='Station_Short', how='outer').fillna(0)
    m_a1['Diff'] = m_a1['cur'] - m_a1['last']

    # --- åˆä½µ A2 ---
    a2_wk = df_wk_clean[['Station_Short', 'A2_Injuries']].rename(columns={'A2_Injuries': 'wk'})
    a2_cur = df_cur_clean[['Station_Short', 'A2_Injuries']].rename(columns={'A2_Injuries': 'cur'})
    a2_lst = df_lst_clean[['Station_Short', 'A2_Injuries']].rename(columns={'A2_Injuries': 'last'})
    
    m_a2 = pd.merge(a2_wk, a2_cur, on='Station_Short', how='outer')
    m_a2 = pd.merge(m_a2, a2_lst, on='Station_Short', how='outer').fillna(0)
    m_a2['Diff'] = m_a2['cur'] - m_a2['last']
    m_a2['Pct'] = m_a2.apply(lambda x: (x['Diff']/x['last']) if x['last']!=0 else 0, axis=1)
    m_a2['Pct_Str'] = m_a2['Pct'].apply(lambda x: f"{x:.2%}")
    m_a2['Prev'] = "-"

    # æ’åº
    m_a1 = sort_stations(m_a1)
    m_a2 = sort_stations(m_a2)

    # æ•´ç†æœ€çµ‚è¡¨æ ¼
    a1_final = m_a1[['Station_Short', 'wk', 'cur', 'last', 'Diff']].copy()
    a1_final.columns = ['å–®ä½', f'æœ¬æœŸ({h_wk})', f'æœ¬å¹´ç´¯è¨ˆ({h_cur})', f'å»å¹´ç´¯è¨ˆ({h_lst})', 'æœ¬å¹´èˆ‡å»å¹´åŒæœŸæ¯”è¼ƒ']
    
    # é¡¯ç¤ºç”¨çš„ A2 è¡¨ (å« % å­—ä¸²)
    a2_display = m_a2[['Station_Short', 'wk', 'Prev', 'cur', 'last', 'Diff', 'Pct_Str']].copy()
    a2_display.columns = ['å–®ä½', f'æœ¬æœŸ({h_wk})', 'å‰æœŸ', f'æœ¬å¹´ç´¯è¨ˆ({h_cur})', f'å»å¹´ç´¯è¨ˆ({h_lst})', 'æœ¬å¹´èˆ‡å»å¹´åŒæœŸæ¯”è¼ƒ', 'æœ¬å¹´è¼ƒå»å¹´å¢æ¸›æ¯”ä¾‹']

    # ä¸‹è¼‰ç”¨çš„ A2 è¡¨ (å« % æ•¸å€¼ï¼Œæ–¹ä¾¿ Excel æ ¼å¼åŒ–)
    a2_download = m_a2[['Station_Short', 'wk', 'Prev', 'cur', 'last', 'Diff', 'Pct']].copy()
    a2_download.columns = ['å–®ä½', f'æœ¬æœŸ({h_wk})', 'å‰æœŸ', f'æœ¬å¹´ç´¯è¨ˆ({h_cur})', f'å»å¹´ç´¯è¨ˆ({h_lst})', 'æœ¬å¹´èˆ‡å»å¹´åŒæœŸæ¯”è¼ƒ', 'æœ¬å¹´è¼ƒå»å¹´å¢æ¸›æ¯”ä¾‹']

    # --- 4. é¡¯ç¤ºçµæœèˆ‡ä¸‹è¼‰æŒ‰éˆ• ---
    st.markdown("### ğŸ“Š çµ±è¨ˆçµæœ")
    
    st.subheader("1. A1 é¡äº¤é€šäº‹æ•…æ­»äº¡äººæ•¸")
    st.dataframe(a1_final, use_container_width=True)
    
    st.subheader("2. A2 é¡äº¤é€šäº‹æ•…å—å‚·äººæ•¸")
    st.dataframe(a2_display, use_container_width=True)

    # ç”¢å‡º Excel
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        a1_final.to_excel(writer, sheet_name='A1æ­»äº¡äººæ•¸', index=False)
        a2_download.to_excel(writer, sheet_name='A2å—å‚·äººæ•¸', index=False)
        
        # è¨­å®š A2 ç™¾åˆ†æ¯”æ ¼å¼
        workbook  = writer.book
        worksheet = writer.sheets['A2å—å‚·äººæ•¸']
        percent_fmt = workbook.add_format({'num_format': '0.00%'})
        worksheet.set_column(6, 6, None, percent_fmt)
        
    output.seek(0)
    
    filename = f'äº¤é€šäº‹æ•…çµ±è¨ˆè¡¨_{datetime.now().strftime("%Y%m%d")}.xlsx'
    
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰æ•´ç†å¥½çš„ Excel å ±è¡¨",
        data=output,
        file_name=filename,
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

def process_data(df_raw):
    """è³‡æ–™æ¸…ç†æ ¸å¿ƒé‚è¼¯"""
    df_data = df_raw[df_raw[0].notna()].copy()
    df_data = df_data[df_data[0].str.contains("ç¸½è¨ˆ|æ´¾å‡ºæ‰€")].copy()
    df_data = df_data.reset_index(drop=True)
    
    columns_map = {
        0: "Station", 1: "Total_Cases", 2: "Total_Deaths", 3: "Total_Injuries",
        4: "A1_Cases", 5: "A1_Deaths", 6: "A1_Injuries",
        7: "A2_Cases", 8: "A2_Deaths", 9: "A2_Injuries", 10: "A3_Cases"
    }
    df_data = df_data.rename(columns=columns_map)
    
    for c in list(columns_map.values()):
        if c not in df_data.columns: df_data[c] = 0
    df_data = df_data[list(columns_map.values())]
    
    for col in list(columns_map.values())[1:]:
        df_data[col] = pd.to_numeric(df_data[col].astype(str).str.replace(",", ""), errors='coerce').fillna(0)
        
    df_data['Station_Short'] = df_data['Station'].str.replace('æ´¾å‡ºæ‰€', 'æ‰€').str.replace('ç¸½è¨ˆ', 'åˆè¨ˆ')
    
    # é‡æ–°è¨ˆç®—åˆè¨ˆ
    df_stations = df_data[~df_data['Station_Short'].str.contains("åˆè¨ˆ")].copy()
    numeric_cols = df_data.columns[1:-1]
    total_row = df_stations[numeric_cols].sum()
    total_row['Station_Short'] = 'åˆè¨ˆ'
    df_total = pd.DataFrame([total_row])
    
    return pd.concat([df_total, df_stations], ignore_index=True)

def sort_stations(df):
    target_order = ['åˆè¨ˆ', 'è–äº­æ‰€', 'é¾æ½­æ‰€', 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ‰€', 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ‰€']
    order_map = {name: i for i, name in enumerate(target_order)}
    df['order'] = df['Station_Short'].map(order_map).fillna(99)
    return df.sort_values('order').drop(columns=['order'])

def format_date(s):
    m = re.findall(r'/(\d{2})/(\d{2})', s)
    return f"{m[0][0]}{m[0][1]}~{m[1][0]}{m[1][1]}" if len(m)>=2 else s

if __name__ == "__main__":
    main()
