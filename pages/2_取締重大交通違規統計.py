import streamlit as st
import pandas as pd
import re
import io
import smtplib
import gspread
import calendar
import pypdf
import numpy as np  # æ–°å¢ numpy ç”¨æ–¼å‹åˆ¥åˆ¤æ–·
from datetime import date
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from email.header import Header

# --- åˆå§‹åŒ–é…ç½® ---
st.set_page_config(page_title="é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ", layout="wide", page_icon="ğŸš¦")
st.title("ğŸš¦ é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ (v65 å¼·åˆ¶è½‰å‹ä¿®å¾©ç‰ˆ)")

# ==========================================
# 0. è¨­å®šå€
# ==========================================
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1HaFu5PZkFDUg7WZGV9khyQ0itdGXhXUakP4_BClFTUg/edit" 
VIOLATION_TARGETS = {'åˆè¨ˆ': 11817, 'ç§‘æŠ€åŸ·æ³•': 0, 'è–äº­æ‰€': 1200, 'é¾æ½­æ‰€': 1500, 'ä¸­èˆˆæ‰€': 1200, 'çŸ³é–€æ‰€': 1000, 'é«˜å¹³æ‰€': 800, 'ä¸‰å’Œæ‰€': 500, 'è­¦å‚™éšŠ': 0, 'äº¤é€šåˆ†éšŠ': 1000}
UNIT_MAP = {'è–äº­æ´¾å‡ºæ‰€': 'è–äº­æ‰€', 'é¾æ½­æ´¾å‡ºæ‰€': 'é¾æ½­æ‰€', 'ä¸­èˆˆæ´¾å‡ºæ‰€': 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ´¾å‡ºæ‰€': 'çŸ³é–€æ‰€', 'é«˜å¹³æ´¾å‡ºæ‰€': 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ´¾å‡ºæ‰€': 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ': 'è­¦å‚™éšŠ', 'é¾æ½­äº¤é€šåˆ†éšŠ': 'äº¤é€šåˆ†éšŠ', 'ç§‘æŠ€åŸ·æ³•': 'ç§‘æŠ€åŸ·æ³•'}
UNIT_ORDER = ['ç§‘æŠ€åŸ·æ³•', 'è–äº­æ‰€', 'é¾æ½­æ‰€', 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ‰€', 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ', 'äº¤é€šåˆ†éšŠ']

# ==========================================
# 1. Google è©¦ç®—è¡¨æ ¼å¼æŒ‡ä»¤
# ==========================================
def get_merge_request(ws_id, start_col, end_col):
    return {"mergeCells": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "mergeType": "MERGE_ALL"}}

def get_center_align_request(ws_id, start_col, end_col):
    return {"repeatCell": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "cell": {"userEnteredFormat": {"horizontalAlignment": "CENTER"}}, "fields": "userEnteredFormat.horizontalAlignment"}}

def get_header_red_req(ws_id, row_idx, col_idx, text):
    red_chars = set("0123456789~().%")
    runs = []
    last_is_red = None
    for i, char in enumerate(text):
        is_red = char in red_chars
        if is_red != last_is_red:
            color = {"red": 1.0, "green": 0, "blue": 0} if is_red else {"red": 0, "green": 0, "blue": 0}
            runs.append({"startIndex": i, "format": {"foregroundColor": color, "bold": is_red}})
            last_is_red = is_red
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

def get_footer_percent_red_req(ws_id, row_idx, col_idx, text):
    runs = [{"startIndex": 0, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}}]
    match = re.search(r'(\d+\.?\d*%)', text)
    if match:
        start, end = match.start(), match.end()
        runs.append({"startIndex": start, "format": {"foregroundColor": {"red": 1.0, "green": 0, "blue": 0}, "bold": True}})
        if end < len(text): runs.append({"startIndex": end, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}})
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

# ==========================================
# 2. æ ¸å¿ƒè§£æå¼•æ“ (å¼·åˆ¶è½‰å‹ä¿®å¾©)
# ==========================================
def to_int(val):
    """å®‰å…¨è½‰æ›ç‚º Python æ¨™æº– int"""
    try:
        # è™•ç† Pandas/Numpy çš„æ•¸å€¼é¡å‹
        if isinstance(val, (np.integer, np.int64, np.int32)):
            return int(val)
        if isinstance(val, (np.floating, float)):
            return int(val)
        # è™•ç†å­—ä¸²
        s = str(val).replace(',', '').strip()
        if s == '' or s == '-' or s == 'nan': return 0
        return int(float(s))
    except:
        return 0

def extract_single_report_data(file_obj):
    counts = {} # {unit: [intercept, report]}
    date_str = "0000~0000"
    
    # åˆ¤æ–·æª”æ¡ˆé¡å‹
    is_pdf = file_obj.name.lower().endswith('.pdf') or (file_obj.name.lower().endswith('.csv') and file_obj.size > 1000)
    
    try:
        # --- A. è™•ç† PDF ---
        if is_pdf:
            reader = pypdf.PdfReader(file_obj)
            text = ""
            for page in reader.pages: text += page.extract_text() + "\n"
            
            # æ—¥æœŸè§£æ
            m = re.search(r'(\d{3,7}).*è‡³\s*(\d{3,7})', text)
            if m: date_str = f"{m.group(1)}~{m.group(2)}"
            
            clean_text = text.replace(')', ' ').replace('(', ' ').replace('%', ' ').replace('\n', ' ')
            for unit in UNIT_ORDER + ['åˆè¨ˆ']:
                try:
                    start = clean_text.find(unit)
                    if start != -1:
                        sub = clean_text[start+len(unit):start+150]
                        tokens = [t.replace(',','') for t in sub.split() if t.replace(',','').replace('-','',1).isdigit()]
                        if len(tokens) >= 3:
                            counts[unit] = [to_int(tokens[1]), to_int(tokens[2])]
                        elif len(tokens) >= 2:
                            counts[unit] = [to_int(tokens[0]), to_int(tokens[1])]
                except: continue
                
        # --- B. è™•ç† Excel ---
        else:
            df = pd.read_excel(file_obj, header=None)
            
            # 1. æ—¥æœŸè§£æ
            top_txt = df.iloc[:10].astype(str).to_string()
            m = re.search(r'(\d{3,7}).*è‡³\s*(\d{3,7})', top_txt)
            if m: date_str = f"{m.group(1)}~{m.group(2)}"
            
            # 2. åº§æ¨™åµæ¸¬ (æ””åœ/é€•è¡Œ)
            idx_int, idx_rem = -1, -1
            # æ“´å¤§æœå°‹ç¯„åœè‡³å‰ 30 è¡Œ
            for r in range(min(30, len(df))):
                row_vals = df.iloc[r].astype(str).tolist()
                for c, val in enumerate(row_vals):
                    v_clean = val.replace('\n', '').replace(' ', '')
                    if "æ””åœ" in v_clean: idx_int = c
                    if "é€•è¡Œ" in v_clean: idx_rem = c
            
            # é è¨­å€¼å‚™æ¡ˆ
            if idx_int == -1: idx_int = 1
            if idx_rem == -1: idx_rem = 2
            
            # 3. æ•¸æ“šæå–
            active_unit = None
            for _, row in df.iterrows():
                row_s = " ".join(row.astype(str))
                
                # å–®ä½è­˜åˆ¥
                if "åˆè¨ˆ" in str(row[0]) or "ç¸½è¨ˆ" in str(row[0]): active_unit = "åˆè¨ˆ"
                elif "ç§‘æŠ€åŸ·æ³•" in str(row[0]): active_unit = "ç§‘æŠ€åŸ·æ³•"
                else:
                    for full, short in UNIT_MAP.items():
                        if short in str(row[0]): active_unit = short; break
                
                if active_unit:
                    v1 = row[idx_int]
                    v2 = row[idx_rem]
                    # å¼·åˆ¶è½‰å‹
                    n1 = to_int(v1)
                    n2 = to_int(v2)
                    counts[active_unit] = [n1, n2]
                    active_unit = None

    except Exception as e:
        print(f"Error: {e}")
        
    return counts, date_str

# ==========================================
# 3. ç•«é¢é¡¯ç¤ºèˆ‡è‡ªå‹•åŒ–
# ==========================================
files = st.file_uploader("è«‹ä¸Šå‚³ 3 å€‹ Focus å ±è¡¨ (Excel/PDF)", accept_multiple_files=True)

if files and len(files) >= 3:
    try:
        # è§£ææª”æ¡ˆ
        parsed_results = []
        for f in files:
            d, date_rng = extract_single_report_data(f)
            parsed_results.append({"file": f, "data": d, "date": date_rng})
        
        # æ’åºæª”æ¡ˆ: æœ¬æœŸ(wk), æœ¬å¹´(yt), å»å¹´(ly)
        f_wk, f_yt, f_ly = None, None, None
        
        # å„ªå…ˆä¾æª”åè¾¨è­˜ (1), (2)
        # è‹¥ç„¡æ¨™è¨˜ï¼Œå‰‡ä¾æ“šæ—¥æœŸå­—ä¸²é•·åº¦æˆ–é †åº
        # é€™è£¡å‡è¨­ä¸Šå‚³é †åºæˆ–æª”ååŒ…å«ç·šç´¢
        for item in parsed_results:
            nm = item['file'].name
            if "(1)" in nm: f_yt = item
            elif "(2)" in nm: f_ly = item
            else: f_wk = item
            
        if not f_yt: f_yt = parsed_results[1]
        if not f_ly: f_ly = parsed_results[2]
        if not f_wk: f_wk = parsed_results[0]

        d_wk = f_wk['data']; title_wk = f"æœ¬æœŸ({f_wk['date']})"
        d_yt = f_yt['data']; title_yt = f"æœ¬å¹´ç´¯è¨ˆ({f_yt['date']})"
        d_ly = f_ly['data']; title_ly = f"å»å¹´ç´¯è¨ˆ({f_ly['date']})"
        
        # æ§‹å»º HTML è¡¨é ­
        def red_h(t): return "".join([f"<span style='color:red; font-weight:bold;'>{c}</span>" if c in "0123456789~().%" else c for c in t])
        html_header = f"""
        <thead>
            <tr>
                <th rowspan='2'>çµ±è¨ˆæœŸé–“</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_wk)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_yt)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_ly)}</th>
                <th rowspan='2'>æœ¬å¹´èˆ‡å»å¹´åŒæœŸæ¯”è¼ƒ</th>
                <th rowspan='2'>ç›®æ¨™å€¼</th>
                <th rowspan='2'>é”æˆç‡</th>
            </tr>
            <tr>
                <th>ç¾å ´æ””åœ</th><th>é€•è¡Œèˆ‰ç™¼</th>
                <th>ç¾å ´æ””åœ</th><th>é€•è¡Œèˆ‰ç™¼</th>
                <th>ç¾å ´æ””åœ</th><th>é€•è¡Œèˆ‰ç™¼</th>
            </tr>
        </thead>
        """

        # æ•¸æ“šçµ„è£ (ç¢ºä¿æ‰€æœ‰æ•¸å€¼çš†ç‚º Python int)
        rows = []
        for u in UNIT_ORDER:
            wk = d_wk.get(u, [0, 0])
            yt = d_yt.get(u, [0, 0])
            ly = d_ly.get(u, [0, 0])
            
            # å¼·åˆ¶è½‰æ›åˆ—è¡¨å…§çš„å…ƒç´ 
            wk = [to_int(x) for x in wk]
            yt = [to_int(x) for x in yt]
            ly = [to_int(x) for x in ly]
            
            yt_tot = sum(yt)
            ly_tot = sum(ly)
            target = VIOLATION_TARGETS.get(u, 0)
            
            rows.append([u, wk[0], wk[1], yt[0], yt[1], ly[0], ly[1], yt_tot - ly_tot, target, f"{yt_tot/target:.0%}" if target > 0 else "â€”"])
        
        # åˆè¨ˆåˆ—è¨ˆç®—
        # ä½¿ç”¨ numpy ä¾†åšå‘é‡åŠ æ³•ï¼Œç¢ºä¿æ¬„ä½å°é½Š
        # ä½†æœ€å¾Œè½‰å› Python list ä»¥é˜² JSON Error
        df_tmp = pd.DataFrame(rows)
        # è½‰æ› df çš„æ•¸æ“šéƒ¨åˆ†ç‚º numeric
        sums = df_tmp.iloc[:, 1:9].apply(pd.to_numeric).sum().fillna(0).astype(int).tolist()
        
        total_target = VIOLATION_TARGETS.get('åˆè¨ˆ', 11817)
        s_yt_tot = sums[2] + sums[3] # æœ¬å¹´æ”” + æœ¬å¹´é€• (ç´¢å¼•åç§»æ³¨æ„: 0=u, 1=wk0, 2=wk1...)
        # ä¿®æ­£ç´¢å¼•: rows çµæ§‹æ˜¯ [unit, wk0, wk1, yt0, yt1, ly0, ly1, ...]
        # DataFrame æ¬„ä½ç´¢å¼•: 0=unit, 1=wk0, 2=wk1, 3=yt0, 4=yt1, 5=ly0, 6=ly1...
        # sums ç´¢å¼•: 0å°æ‡‰df col 1 (wk0)...
        
        # é‡æ–°ç²¾ç®—åˆè¨ˆ
        t_wk0 = sum([r[1] for r in rows])
        t_wk1 = sum([r[2] for r in rows])
        t_yt0 = sum([r[3] for r in rows])
        t_yt1 = sum([r[4] for r in rows])
        t_ly0 = sum([r[5] for r in rows])
        t_ly1 = sum([r[6] for r in rows])
        t_diff = (t_yt0 + t_yt1) - (t_ly0 + t_ly1)
        
        total_row = ["åˆè¨ˆ", t_wk0, t_wk1, t_yt0, t_yt1, t_ly0, t_ly1, t_diff, total_target, f"{(t_yt0+t_yt1)/total_target:.0%}" if total_target > 0 else "0%"]
        
        method_row = ["å–ç· æ–¹å¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "", "", ""]
        all_rows = [method_row, total_row] + rows
        
        st.success("âœ… æ•¸æ“šè§£ææˆåŠŸ (æ ¼å¼å·²ä¿®å¾©)")
        
        # é¡¯ç¤º
        table_body = "".join([f"<tr>{''.join([f'<td>{x}</td>' for x in r])}</tr>" for r in all_rows])
        st.write(f"<table>{html_header}<tbody>{table_body}</tbody></table>", unsafe_allow_html=True)

        # èªªæ˜
        try:
            curr_year = date.today().year
            d_str = f_yt['date'].split('~')[1]
            mon = int(d_str[:2]); day = int(d_str[2:])
            prog = f"{((date(curr_year, mon, day) - date(curr_year, 1, 1)).days + 1) / (366 if calendar.isleap(curr_year) else 365):.1%}"
            e_yt_str = f"{curr_year-1911}å¹´{mon}æœˆ{day}æ—¥"
        except: 
            prog = "98.0%"; e_yt_str = "114å¹´12æœˆXXæ—¥"

        f1 = f"ä¸€ã€æœ¬æœŸå®šç¾©ï¼šä¿‚æŒ‡è©²æœŸæ˜±é€šç³»çµ±å…¥æ¡ˆä»¶æ•¸ï¼›ä»¥å¹´åº•é”æˆç‡100%ç‚ºåŸºæº–ï¼Œçµ±è¨ˆæˆªè‡³ {e_yt_str} (å…¥æ¡ˆæ—¥æœŸ)æ‡‰é”æˆç‡ç‚º{prog}ã€‚"
        f2 = "äºŒã€é‡å¤§äº¤é€šé•è¦æŒ‡ï¼šã€Œé—–ç´…ç‡ˆã€ã€ã€Œé…’å¾Œé§•è»Šã€ã€ã€Œåš´é‡è¶…é€Ÿã€ã€ã€Œæœªä¾å…©æ®µå¼å·¦è½‰ã€ã€ã€Œä¸æš«åœè®“è¡Œäººã€ã€ ã€Œé€†å‘è¡Œé§›ã€ã€ã€Œè½‰å½æœªä¾è¦å®šã€ã€ã€Œè›‡è¡Œã€æƒ¡æ„é€¼è»Šã€ç­‰8é …ã€‚"
        st.markdown(f"<br>#### {f1.replace(prog, f':red[{prog}]')}\n#### {f2}", unsafe_allow_html=True)

        # è‡ªå‹•åŒ–åŒæ­¥
        file_hash = "".join([f.name + str(f.size) for f in files])
        if st.session_state.get("v65_done") != file_hash:
            with st.status("ğŸš€ åŸ·è¡Œè‡ªå‹•åŒ–åŒæ­¥...") as s:
                gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
                sh = gc.open_by_url(GOOGLE_SHEET_URL); ws = sh.get_worksheet(0)
                
                # æº–å‚™ Payload (å†æ¬¡ç¢ºä¿æ‰€æœ‰æ•¸å€¼ç‚º Native Python Types)
                h1_raw = ["çµ±è¨ˆæœŸé–“", title_wk, "", title_yt, "", title_ly, "", "åŒæœŸæ¯”è¼ƒ", "ç›®æ¨™å€¼", "é”æˆç‡"]
                
                # è½‰æ› all_rows å…§çš„ numpy.int64 ç‚º int
                clean_rows = []
                for row in all_rows:
                    new_row = [to_int(x) if isinstance(x, (int, float, np.number)) else str(x) for x in row]
                    clean_rows.append(new_row)
                
                full_payload = [h1_raw] + clean_rows
                
                ws.update(range_name='A2', values=full_payload)
                
                reqs = []
                for col_p in [(1,3), (3,5), (5,7)]:
                    reqs.append(get_merge_request(ws.id, col_p[0], col_p[1]))
                    reqs.append(get_center_align_request(ws.id, col_p[0], col_p[1]))
                
                for i, txt in [(2, title_wk), (4, title_yt), (6, title_ly)]:
                    reqs.append(get_header_red_req(ws.id, 2, i, txt))
                
                idx_f = 2 + len(full_payload) + 1
                ws.update_cell(idx_f, 1, f1); ws.update_cell(idx_f+1, 1, f2)
                reqs.append(get_footer_percent_red_req(ws.id, idx_f, 1, f1))
                
                sh.batch_update({"requests": reqs})
                
                if "email" in st.secrets:
                    out = io.BytesIO(); pd.DataFrame(full_payload).to_excel(out, index=False)
                    server = smtplib.SMTP('smtp.gmail.com', 587); server.starttls()
                    server.login(st.secrets["email"]["user"], st.secrets["email"]["password"])
                    msg = MIMEMultipart(); msg['Subject'] = Header(f"ğŸš¦ Focus å ±è¡¨ - {e_yt_str}", "utf-8").encode()
                    msg.attach(MIMEText(f"{f1}\n{f2}", "plain"))
                    part = MIMEBase("application", "octet-stream"); part.set_payload(out.getvalue())
                    encoders.encode_base64(part); part.add_header("Content-Disposition", 'attachment; filename="Report.xlsx"')
                    msg.attach(part); server.send_message(msg); server.quit()
                
                st.session_state["v65_done"] = file_hash
                st.balloons(); s.update(label="å®Œæˆ", state="complete")
    except Exception as e: st.error(f"éŒ¯èª¤: {e}")
