import streamlit as st
import pandas as pd
import re
import io
import smtplib
import gspread
import calendar
import pypdf
import numpy as np
from datetime import date
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from email.header import Header

# --- åˆå§‹åŒ–é…ç½® ---
st.set_page_config(page_title="é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ", layout="wide", page_icon="ğŸš¦")
st.title("ğŸš¦ é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ (v66 å–®å±¤æ¨™é ­ç‰ˆ)")

# ==========================================
# 0. è¨­å®šå€
# ==========================================
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1HaFu5PZkFDUg7WZGV9khyQ0itdGXhXUakP4_BClFTUg/edit" 
VIOLATION_TARGETS = {'åˆè¨ˆ': 11817, 'ç§‘æŠ€åŸ·æ³•': 0, 'è–äº­æ‰€': 1200, 'é¾æ½­æ‰€': 1500, 'ä¸­èˆˆæ‰€': 1200, 'çŸ³é–€æ‰€': 1000, 'é«˜å¹³æ‰€': 800, 'ä¸‰å’Œæ‰€': 500, 'è­¦å‚™éšŠ': 0, 'äº¤é€šåˆ†éšŠ': 1000}
UNIT_MAP = {'è–äº­æ´¾å‡ºæ‰€': 'è–äº­æ‰€', 'é¾æ½­æ´¾å‡ºæ‰€': 'é¾æ½­æ‰€', 'ä¸­èˆˆæ´¾å‡ºæ‰€': 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ´¾å‡ºæ‰€': 'çŸ³é–€æ‰€', 'é«˜å¹³æ´¾å‡ºæ‰€': 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ´¾å‡ºæ‰€': 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ': 'è­¦å‚™éšŠ', 'é¾æ½­äº¤é€šåˆ†éšŠ': 'äº¤é€šåˆ†éšŠ', 'ç§‘æŠ€åŸ·æ³•': 'ç§‘æŠ€åŸ·æ³•'}
UNIT_ORDER = ['ç§‘æŠ€åŸ·æ³•', 'è–äº­æ‰€', 'é¾æ½­æ‰€', 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ‰€', 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ', 'äº¤é€šåˆ†éšŠ']

# ==========================================
# 1. Google è©¦ç®—è¡¨æ ¼å¼æŒ‡ä»¤
# ==========================================
def get_merge_request(ws_id, start_col, end_col):
    return {"mergeCells": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "mergeType": "MERGE_ALL"}}

def get_center_align_request(ws_id, start_col, end_col):
    return {"repeatCell": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "cell": {"userEnteredFormat": {"horizontalAlignment": "CENTER"}}, "fields": "userEnteredFormat.horizontalAlignment"}}

def get_header_red_req(ws_id, row_idx, col_idx, text):
    red_chars = set("0123456789~().%")
    runs = []
    last_is_red = None
    for i, char in enumerate(text):
        is_red = char in red_chars
        if is_red != last_is_red:
            color = {"red": 1.0, "green": 0, "blue": 0} if is_red else {"red": 0, "green": 0, "blue": 0}
            runs.append({"startIndex": i, "format": {"foregroundColor": color, "bold": is_red}})
            last_is_red = is_red
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

def get_footer_percent_red_req(ws_id, row_idx, col_idx, text):
    runs = [{"startIndex": 0, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}}]
    match = re.search(r'(\d+\.?\d*%)', text)
    if match:
        start, end = match.start(), match.end()
        runs.append({"startIndex": start, "format": {"foregroundColor": {"red": 1.0, "green": 0, "blue": 0}, "bold": True}})
        if end < len(text): runs.append({"startIndex": end, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}})
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

# ==========================================
# 2. æ ¸å¿ƒè§£æå¼•æ“ (PDF / Excel / CSV æ”¯æ´)
# ==========================================
def to_int(val):
    try:
        if isinstance(val, (np.integer, np.int64, np.int32, np.floating, float)):
            return int(val)
        s = str(val).replace(',', '').strip()
        if s == '' or s == '-' or s == 'nan': return 0
        return int(float(s))
    except: return 0

def extract_single_report_data(file_obj):
    counts = {}
    date_str = "0000~0000"
    
    # åˆ¤æ–·æ˜¯å¦ç‚º PDF (ä¾æª”åæˆ–å…§å®¹)
    is_pdf = file_obj.name.lower().endswith('.pdf')
    
    try:
        # --- A. PDF è§£æ ---
        if is_pdf:
            reader = pypdf.PdfReader(file_obj)
            text = ""
            for page in reader.pages: text += page.extract_text() + "\n"
            m = re.search(r'(\d{3,7}).*è‡³\s*(\d{3,7})', text)
            if m: date_str = f"{m.group(1)}~{m.group(2)}"
            
            clean_text = text.replace(')', ' ').replace('(', ' ').replace('%', ' ').replace('\n', ' ')
            for unit in UNIT_ORDER + ['åˆè¨ˆ']:
                try:
                    start = clean_text.find(unit)
                    if start != -1:
                        sub = clean_text[start+len(unit):start+150]
                        tokens = [t.replace(',','') for t in sub.split() if t.replace(',','').replace('-','',1).isdigit()]
                        if len(tokens) >= 3: counts[unit] = [to_int(tokens[1]), to_int(tokens[2])]
                        elif len(tokens) >= 2: counts[unit] = [to_int(tokens[0]), to_int(tokens[1])]
                except: continue
                
        # --- B. Excel / CSV è§£æ ---
        else:
            try:
                # å„ªå…ˆå˜—è©¦ Excel
                df = pd.read_excel(file_obj, header=None)
            except:
                # å¤±æ•—å‰‡å˜—è©¦ CSV
                file_obj.seek(0)
                try:
                    df = pd.read_csv(file_obj, header=None, encoding='utf-8')
                except:
                    file_obj.seek(0)
                    df = pd.read_csv(file_obj, header=None, encoding='big5') # å˜—è©¦ Big5 ç·¨ç¢¼

            # 1. æŠ“å–æ—¥æœŸ
            top_txt = df.iloc[:10].astype(str).to_string()
            m = re.search(r'(\d{3,7}).*è‡³\s*(\d{3,7})', top_txt)
            if m: date_str = f"{m.group(1)}~{m.group(2)}"
            
            # 2. åº§æ¨™åµæ¸¬
            idx_int, idx_rem = -1, -1
            for r in range(min(30, len(df))):
                row_vals = df.iloc[r].astype(str).tolist()
                for c, val in enumerate(row_vals):
                    v = val.replace('\n', '').replace(' ', '')
                    if "æ””åœ" in v: idx_int = c
                    if "é€•è¡Œ" in v: idx_rem = c
            
            if idx_int == -1: idx_int = 1
            if idx_rem == -1: idx_rem = 2
            
            # 3. æ•¸æ“šæå–
            active_unit = None
            for _, row in df.iterrows():
                row_s = " ".join(row.astype(str))
                if "åˆè¨ˆ" in str(row[0]) or "ç¸½è¨ˆ" in str(row[0]): active_unit = "åˆè¨ˆ"
                elif "ç§‘æŠ€åŸ·æ³•" in str(row[0]): active_unit = "ç§‘æŠ€åŸ·æ³•"
                else:
                    for full, short in UNIT_MAP.items():
                        if short in str(row[0]): active_unit = short; break
                
                if active_unit:
                    try:
                        counts[active_unit] = [to_int(row[idx_int]), to_int(row[idx_rem])]
                    except: pass
                    active_unit = None

    except Exception as e: print(f"è§£æéŒ¯èª¤ {file_obj.name}: {e}")
        
    return counts, date_str

# ==========================================
# 3. ç•«é¢é¡¯ç¤ºèˆ‡è‡ªå‹•åŒ–
# ==========================================
files = st.file_uploader("è«‹ä¸Šå‚³ 3 å€‹ Focus å ±è¡¨ (Excel/CSV/PDF)", accept_multiple_files=True)

if files and len(files) >= 3:
    try:
        # è§£æèˆ‡åˆ†é¡ (wk, yt, ly)
        parsed_results = []
        for f in files:
            d, date_rng = extract_single_report_data(f)
            parsed_results.append({"file": f, "data": d, "date": date_rng})
        
        f_wk, f_yt, f_ly = None, None, None
        for item in parsed_results:
            nm = item['file'].name
            if "(1)" in nm: f_yt = item
            elif "(2)" in nm: f_ly = item
            else: f_wk = item
            
        if not f_yt: f_yt = parsed_results[1]
        if not f_ly: f_ly = parsed_results[2]
        if not f_wk: f_wk = parsed_results[0]

        d_wk = f_wk['data']; title_wk = f"æœ¬æœŸ({f_wk['date']})"
        d_yt = f_yt['data']; title_yt = f"æœ¬å¹´ç´¯è¨ˆ({f_yt['date']})"
        d_ly = f_ly['data']; title_ly = f"å»å¹´ç´¯è¨ˆ({f_ly['date']})"
        
        # ğŸš€ å–®å±¤ HTML è¡¨é ­ (ç§»é™¤åŸæœ¬çš„ç¬¬äºŒåˆ—)
        def red_h(t): return "".join([f"<span style='color:red; font-weight:bold;'>{c}</span>" if c in "0123456789~().%" else c for c in t])
        
        html_header = f"""
        <thead>
            <tr>
                <th>çµ±è¨ˆæœŸé–“</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_wk)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_yt)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_ly)}</th>
                <th>åŒæœŸæ¯”è¼ƒ</th>
                <th>ç›®æ¨™å€¼</th>
                <th>é”æˆç‡</th>
            </tr>
        </thead>
        """

        # æ•¸æ“šçµ„è£
        rows = []
        for u in UNIT_ORDER:
            wk = d_wk.get(u, [0, 0]); yt = d_yt.get(u, [0, 0]); ly = d_ly.get(u, [0, 0])
            yt_tot = sum(yt); ly_tot = sum(ly); target = VIOLATION_TARGETS.get(u, 0)
            rows.append([u, wk[0], wk[1], yt[0], yt[1], ly[0], ly[1], yt_tot - ly_tot, target, f"{yt_tot/target:.0%}" if target > 0 else "â€”"])
        
        # åˆè¨ˆåˆ—è¨ˆç®—
        df_tmp = pd.DataFrame(rows)
        sums = df_tmp.iloc[:, 1:9].apply(pd.to_numeric).sum().fillna(0).astype(int).tolist()
        total_target = VIOLATION_TARGETS.get('åˆè¨ˆ', 11817)
        s_yt_tot = sums[2] + sums[3]
        total_row = ["åˆè¨ˆ", sums[1], sums[2], sums[3], sums[4], sums[5], sums[6], sums[7], total_target, f"{s_yt_tot/total_target:.0%}" if total_target > 0 else "0%"]
        
        # å–ç· æ–¹å¼åˆ—
        method_row = ["å–ç· æ–¹å¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "", "", ""]
        all_rows = [method_row, total_row] + rows
        
        st.success("âœ… è§£ææˆåŠŸï¼æ¨™é ­å·²ç°¡åŒ–ã€‚")
        
        # æ¸²æŸ“
        table_body = "".join([f"<tr>{''.join([f'<td>{x}</td>' for x in r])}</tr>" for r in all_rows])
        st.write(f"<table style='text-align:center; width:100%;'>{html_header}<tbody>{table_body}</tbody></table>", unsafe_allow_html=True)

        # èªªæ˜
        try:
            curr_year = date.today().year
            d_str = f_yt['date'].split('~')[1]
            mon = int(d_str[:2]); day = int(d_str[2:])
            prog = f"{((date(curr_year, mon, day) - date(curr_year, 1, 1)).days + 1) / (366 if calendar.isleap(curr_year) else 365):.1%}"
            e_yt_str = f"{curr_year-1911}å¹´{mon}æœˆ{day}æ—¥"
        except: 
            prog = "98.0%"; e_yt_str = "114å¹´12æœˆXXæ—¥"

        f1 = f"ä¸€ã€æœ¬æœŸå®šç¾©ï¼šä¿‚æŒ‡è©²æœŸæ˜±é€šç³»çµ±å…¥æ¡ˆä»¶æ•¸ï¼›ä»¥å¹´åº•é”æˆç‡100%ç‚ºåŸºæº–ï¼Œçµ±è¨ˆæˆªè‡³ {e_yt_str} (å…¥æ¡ˆæ—¥æœŸ)æ‡‰é”æˆç‡ç‚º{prog}ã€‚"
        f2 = "äºŒã€é‡å¤§äº¤é€šé•è¦æŒ‡ï¼šã€Œé—–ç´…ç‡ˆã€ã€ã€Œé…’å¾Œé§•è»Šã€ã€ã€Œåš´é‡è¶…é€Ÿã€ã€ã€Œæœªä¾å…©æ®µå¼å·¦è½‰ã€ã€ã€Œä¸æš«åœè®“è¡Œäººã€ã€ ã€Œé€†å‘è¡Œé§›ã€ã€ã€Œè½‰å½æœªä¾è¦å®šã€ã€ã€Œè›‡è¡Œã€æƒ¡æ„é€¼è»Šã€ç­‰8é …ã€‚"
        st.markdown(f"<br>#### {f1.replace(prog, f':red[{prog}]')}\n#### {f2}", unsafe_allow_html=True)

        # è‡ªå‹•åŒ–åŒæ­¥
        file_hash = "".join([f.name + str(f.size) for f in files])
        if st.session_state.get("v66_done") != file_hash:
            with st.status("ğŸš€ åŸ·è¡Œè‡ªå‹•åŒ–åŒæ­¥...") as s:
                gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
                sh = gc.open_by_url(GOOGLE_SHEET_URL); ws = sh.get_worksheet(0)
                
                h1_raw = ["çµ±è¨ˆæœŸé–“", title_wk, "", title_yt, "", title_ly, "", "åŒæœŸæ¯”è¼ƒ", "ç›®æ¨™å€¼", "é”æˆç‡"]
                # å°‡æ‰€æœ‰æ•¸å€¼è½‰ç‚º int ä»¥é˜² JSON Error
                clean_rows = [[to_int(x) if isinstance(x, (int, float, np.number)) else str(x) for x in r] for r in all_rows]
                
                full_payload = [h1_raw] + clean_rows
                ws.update(range_name='A2', values=full_payload)
                
                reqs = []
                # åˆä½µæ¨™é ­ B2:C2, D2:E2, F2:G2
                for col_p in [(1,3), (3,5), (5,7)]:
                    reqs.append(get_merge_request(ws.id, col_p[0], col_p[1]))
                    reqs.append(get_center_align_request(ws.id, col_p[0], col_p[1]))
                
                for i, txt in [(2, title_wk), (4, title_yt), (6, title_ly)]:
                    reqs.append(get_header_red_req(ws.id, 2, i, txt))
                
                idx_f = 2 + len(full_payload) + 1
                ws.update_cell(idx_f, 1, f1); ws.update_cell(idx_f+1, 1, f2)
                reqs.append(get_footer_percent_red_req(ws.id, idx_f, 1, f1))
                
                sh.batch_update({"requests": reqs})
                
                if "email" in st.secrets:
                    out = io.BytesIO(); pd.DataFrame(full_payload).to_excel(out, index=False)
                    server = smtplib.SMTP('smtp.gmail.com', 587); server.starttls()
                    server.login(st.secrets["email"]["user"], st.secrets["email"]["password"])
                    msg = MIMEMultipart(); msg['Subject'] = Header(f"ğŸš¦ Focus å ±è¡¨ - {e_yt_str}", "utf-8").encode()
                    msg.attach(MIMEText(f"{f1}\n{f2}", "plain"))
                    part = MIMEBase("application", "octet-stream"); part.set_payload(out.getvalue())
                    encoders.encode_base64(part); part.add_header("Content-Disposition", 'attachment; filename="Violations.xlsx"')
                    msg.attach(part); server.send_message(msg); server.quit()
                
                st.session_state["v66_done"] = file_hash
                st.balloons(); s.update(label="å®Œæˆ", state="complete")
    except Exception as e: st.error(f"éŒ¯èª¤: {e}")
