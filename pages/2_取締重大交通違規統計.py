import streamlit as st
import pandas as pd
import re
import io
import smtplib
import gspread
import calendar
import pypdf
import numpy as np
import traceback
import csv
from datetime import date
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from email.header import Header

# --- åˆå§‹åŒ–é…ç½® ---
st.set_page_config(page_title="é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ", layout="wide", page_icon="ğŸš¦")
st.title("ğŸš¦ é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ (v70 ç²¾æº–å°ä½ç‰ˆ)")

# ==========================================
# 0. è¨­å®šå€
# ==========================================
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1HaFu5PZkFDUg7WZGV9khyQ0itdGXhXUakP4_BClFTUg/edit" 

# ä¿®æ”¹ï¼šç§‘æŠ€åŸ·æ³• å³ äº¤é€šçµ„
# é€™è£¡çš„ Key æ˜¯æˆ‘å€‘å ±è¡¨ä¸Šè¦é¡¯ç¤ºçš„åç¨±ï¼ŒValue æ˜¯ CSV æª”è£¡å¯èƒ½å‡ºç¾çš„åç¨±
UNIT_MAP = {
    'è–äº­æ´¾å‡ºæ‰€': 'è–äº­æ‰€', 'é¾æ½­æ´¾å‡ºæ‰€': 'é¾æ½­æ‰€', 'ä¸­èˆˆæ´¾å‡ºæ‰€': 'ä¸­èˆˆæ‰€', 
    'çŸ³é–€æ´¾å‡ºæ‰€': 'çŸ³é–€æ‰€', 'é«˜å¹³æ´¾å‡ºæ‰€': 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ´¾å‡ºæ‰€': 'ä¸‰å’Œæ‰€', 
    'è­¦å‚™éšŠ': 'è­¦å‚™éšŠ', 'é¾æ½­äº¤é€šåˆ†éšŠ': 'äº¤é€šåˆ†éšŠ', 'äº¤é€šä¸­éšŠ': 'äº¤é€šåˆ†éšŠ',
    'ç§‘æŠ€åŸ·æ³•': 'ç§‘æŠ€åŸ·æ³•', 'äº¤é€šçµ„': 'ç§‘æŠ€åŸ·æ³•' # è‹¥ CSV å‡ºç¾äº¤é€šçµ„ï¼Œè¦–ç‚ºç§‘æŠ€åŸ·æ³•
}

# å ±è¡¨é¡¯ç¤ºé †åº
UNIT_ORDER = ['ç§‘æŠ€åŸ·æ³•', 'è–äº­æ‰€', 'é¾æ½­æ‰€', 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ‰€', 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ', 'äº¤é€šåˆ†éšŠ']

VIOLATION_TARGETS = {'åˆè¨ˆ': 11817, 'ç§‘æŠ€åŸ·æ³•': 0, 'è–äº­æ‰€': 1200, 'é¾æ½­æ‰€': 1500, 'ä¸­èˆˆæ‰€': 1200, 'çŸ³é–€æ‰€': 1000, 'é«˜å¹³æ‰€': 800, 'ä¸‰å’Œæ‰€': 500, 'è­¦å‚™éšŠ': 0, 'äº¤é€šåˆ†éšŠ': 1000}

# ==========================================
# 1. Google è©¦ç®—è¡¨æ ¼å¼æŒ‡ä»¤
# ==========================================
def get_merge_request(ws_id, start_col, end_col):
    return {"mergeCells": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "mergeType": "MERGE_ALL"}}

def get_center_align_request(ws_id, start_col, end_col):
    return {"repeatCell": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "cell": {"userEnteredFormat": {"horizontalAlignment": "CENTER"}}, "fields": "userEnteredFormat.horizontalAlignment"}}

def get_header_red_req(ws_id, row_idx, col_idx, text):
    red_chars = set("0123456789~().%")
    runs = []
    text_str = str(text)
    last_is_red = None
    for i, char in enumerate(text_str):
        is_red = char in red_chars
        if is_red != last_is_red:
            color = {"red": 1.0, "green": 0, "blue": 0} if is_red else {"red": 0, "green": 0, "blue": 0}
            runs.append({"startIndex": i, "format": {"foregroundColor": color, "bold": is_red}})
            last_is_red = is_red
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text_str}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

def get_footer_percent_red_req(ws_id, row_idx, col_idx, text):
    runs = [{"startIndex": 0, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}}]
    text_str = str(text)
    match = re.search(r'(\d+\.?\d*%)', text_str)
    if match:
        start, end = match.start(), match.end()
        runs.append({"startIndex": start, "format": {"foregroundColor": {"red": 1.0, "green": 0, "blue": 0}, "bold": True}})
        if end < len(text_str): runs.append({"startIndex": end, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}})
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text_str}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

# ==========================================
# 2. æ ¸å¿ƒè§£æå¼•æ“ (é‡å° CSV/æ•´åˆå ±è¡¨å„ªåŒ–)
# ==========================================
def clean_int(val):
    try:
        if pd.isna(val) or str(val).strip() in ['â€”', '', '-', 'nan']: return 0
        s = str(val).replace(',', '').strip()
        return int(float(s))
    except: return 0

def parse_integrated_csv(file_obj):
    """è§£ææ•´åˆå‹ CSV å ±è¡¨"""
    counts = {} # {unit: [wk_int, wk_rem, yt_int, yt_rem, ly_int, ly_rem]}
    dates = {"wk": "0000~0000", "yt": "0000~0000", "ly": "0000~0000"}
    
    try:
        file_obj.seek(0)
        # å˜—è©¦è®€å– CSVï¼Œå¿½ç•¥éŒ¯èª¤è¡Œ
        try:
            df = pd.read_csv(file_obj, header=None, on_bad_lines='skip', encoding='utf-8')
        except:
            file_obj.seek(0)
            df = pd.read_csv(file_obj, header=None, on_bad_lines='skip', encoding='big5')

        # 1. æŠ“å–æ—¥æœŸ (é€šå¸¸åœ¨ç¬¬ 2 åˆ—)
        header_text = df.iloc[:5].astype(str).to_string()
        m_wk = re.search(r'æœ¬æœŸ\((\d+~\d+)\)', header_text)
        m_yt = re.search(r'æœ¬å¹´ç´¯è¨ˆ\((\d+~\d+)\)', header_text)
        m_ly = re.search(r'å»å¹´ç´¯è¨ˆ\((\d+~\d+)\)', header_text)
        if m_wk: dates["wk"] = m_wk.group(1)
        if m_yt: dates["yt"] = m_yt.group(1)
        if m_ly: dates["ly"] = m_ly.group(1)
        
        # 2. å®šä½ã€Œå–ç· æ–¹å¼ã€é‚£ä¸€åˆ—
        # æ ¹æ“šæ‚¨çš„ CSV snippetï¼Œæ•¸æ“šé€šå¸¸åœ¨ã€Œå–ç· æ–¹å¼ã€åˆ—çš„ä¸‹æ–¹
        start_row = -1
        for idx, row in df.iterrows():
            if "å–ç· æ–¹å¼" in str(row.values) and "ç¾å ´æ””åœ" in str(row.values):
                start_row = idx
                break
        
        if start_row == -1: return {}, dates # æ‰¾ä¸åˆ°å®šä½é»

        # 3. æŠ“å–æ•¸æ“š (å‡è¨­æ””åœèˆ‡é€•è¡Œäº¤éŒ¯æ’åˆ—)
        # CSV æ¬„ä½é †åºé æ¸¬: [å–®ä½, æœ¬æœŸæ””, æœ¬æœŸé€•, æœ¬å¹´æ””, æœ¬å¹´é€•, å»å¹´æ””, å»å¹´é€•...]
        # æ ¹æ“šæ‚¨çš„ snippet: 
        # åˆè¨ˆ, 18, 297, 2787, 15180, 2327, 15738...
        # ç´¢å¼•: 0, 1, 2, 3, 4, 5, 6
        
        for idx in range(start_row + 1, len(df)):
            row = df.iloc[idx].tolist()
            row_str = "".join([str(x) for x in row])
            
            # è¾¨è­˜å–®ä½
            found_unit = None
            if "åˆè¨ˆ" in str(row[0]): found_unit = "åˆè¨ˆ"
            elif "ç§‘æŠ€åŸ·æ³•" in str(row[0]) or "äº¤é€šçµ„" in str(row[0]): found_unit = "ç§‘æŠ€åŸ·æ³•"
            else:
                for full, short in UNIT_MAP.items():
                    if short in str(row[0]): found_unit = short; break
            
            if found_unit:
                # ä¾åºæŠ“å– 6 å€‹æ•¸å­—
                # æ³¨æ„ï¼šCSV è®€é€²ä¾†å¯èƒ½æœƒæœ‰ç©ºæ¬„ä½ï¼Œéœ€éæ¿¾
                # é€™è£¡å‡è¨­ç¬¬ 1 æ¬„æ˜¯å–®ä½åç¨±ï¼Œæ¥è‘—å°±æ˜¯æ•¸æ“š
                nums = []
                for cell in row[1:]:
                    if pd.notna(cell) and str(cell).strip() != '':
                        nums.append(clean_int(cell))
                
                # è£œé½Šè‡³ 6 å€‹
                while len(nums) < 6: nums.append(0)
                
                counts[found_unit] = nums[:6] # å–å‰ 6 å€‹: wk_i, wk_r, yt_i, yt_r, ly_i, ly_r

    except Exception as e:
        print(f"CSV è§£æå¤±æ•—: {e}")

    return counts, dates

# ==========================================
# 3. ç•«é¢é¡¯ç¤ºèˆ‡è‡ªå‹•åŒ–
# ==========================================
files = st.file_uploader("è«‹ä¸Šå‚³æ•´åˆå‹å ±è¡¨ (CSV/Excel)", accept_multiple_files=True)

if files:
    try:
        # åªè™•ç†é‚£å€‹æ•´åˆ CSV
        target_file = files[0] # å‡è¨­ä½¿ç”¨è€…åªä¸Šå‚³è©²æª”æ¡ˆ
        
        data_map, date_map = parse_integrated_csv(target_file)
        
        if not data_map:
            st.error("âŒ ç„¡æ³•æŠ“å–æ•¸æ“šï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼æ˜¯å¦ç‚ºæ•´åˆå‹ CSVã€‚")
            st.stop()

        # æ¨™é¡Œæ—¥æœŸ
        title_wk = f"æœ¬æœŸ({date_map['wk']})"
        title_yt = f"æœ¬å¹´ç´¯è¨ˆ({date_map['yt']})"
        title_ly = f"å»å¹´ç´¯è¨ˆ({date_map['ly']})"
        
        def red_h(t): return "".join([f"<span style='color:red; font-weight:bold;'>{c}</span>" if c in "0123456789~().%" else c for c in t])
        
        html_header = f"""
        <thead>
            <tr>
                <th>çµ±è¨ˆæœŸé–“</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_wk)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_yt)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_ly)}</th>
                <th>åŒæœŸæ¯”è¼ƒ</th>
                <th>ç›®æ¨™å€¼</th>
                <th>é”æˆç‡</th>
            </tr>
        </thead>
        """

        rows = []
        for u in UNIT_ORDER:
            # vals: [wk_int, wk_rem, yt_int, yt_rem, ly_int, ly_rem]
            vals = data_map.get(u, [0, 0, 0, 0, 0, 0])
            yt_tot = vals[2] + vals[3]
            ly_tot = vals[4] + vals[5]
            target = VIOLATION_TARGETS.get(u, 0)
            rows.append([u, vals[0], vals[1], vals[2], vals[3], vals[4], vals[5], yt_tot - ly_tot, target, f"{yt_tot/target:.0%}" if target > 0 else "â€”"])
        
        # åˆè¨ˆåˆ—
        if 'åˆè¨ˆ' in data_map:
            s = data_map['åˆè¨ˆ']
            s_yt = s[2] + s[3]; s_ly = s[4] + s[5]
            total_target = VIOLATION_TARGETS.get('åˆè¨ˆ', 11817)
            total_row = ["åˆè¨ˆ", s[0], s[1], s[2], s[3], s[4], s[5], s_yt - s_ly, total_target, f"{s_yt/total_target:.0%}" if total_target > 0 else "0%"]
        else:
            # è‡ªå‹•è¨ˆç®—
            df_tmp = pd.DataFrame(rows)
            sums = df_tmp.iloc[:, 1:7].sum().tolist()
            s_yt = sums[2] + sums[3]; s_ly = sums[4] + sums[5]
            total_target = 11817
            total_row = ["åˆè¨ˆ", sums[0], sums[1], sums[2], sums[3], sums[4], sums[5], s_yt - s_ly, total_target, f"{s_yt/total_target:.0%}"]

        method_row = ["å–ç· æ–¹å¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "", "", ""]
        all_rows = [method_row, total_row] + rows
        
        st.success("âœ… æ•¸æ“šæŠ“å–æˆåŠŸï¼(v70 ç²¾æº–å°ä½)")
        
        # æ¸²æŸ“
        table_body = "".join([f"<tr>{''.join([f'<td>{x}</td>' for x in r])}</tr>" for r in all_rows])
        st.write(f"<table style='text-align:center; width:100%; border-collapse:collapse;' border='1'>{html_header}<tbody>{table_body}</tbody></table>", unsafe_allow_html=True)

        # èªªæ˜
        try:
            curr_year = date.today().year
            d_str = date_map['yt'].split('~')[1]
            mon = int(d_str[:2]); day = int(d_str[2:])
            prog = f"{((date(curr_year, mon, day) - date(curr_year, 1, 1)).days + 1) / (366 if calendar.isleap(curr_year) else 365):.1%}"
            e_yt_str = f"{curr_year-1911}å¹´{mon}æœˆ{day}æ—¥"
        except: prog = "98.0%"; e_yt_str = "114å¹´12æœˆXXæ—¥"

        f1 = f"ä¸€ã€æœ¬æœŸå®šç¾©ï¼šä¿‚æŒ‡è©²æœŸæ˜±é€šç³»çµ±å…¥æ¡ˆä»¶æ•¸ï¼›ä»¥å¹´åº•é”æˆç‡100%ç‚ºåŸºæº–ï¼Œçµ±è¨ˆæˆªè‡³ {e_yt_str} (å…¥æ¡ˆæ—¥æœŸ)æ‡‰é”æˆç‡ç‚º{prog}ã€‚"
        f2 = "äºŒã€é‡å¤§äº¤é€šé•è¦æŒ‡ï¼šã€Œé—–ç´…ç‡ˆã€ã€ã€Œé…’å¾Œé§•è»Šã€ã€ã€Œåš´é‡è¶…é€Ÿã€ã€ã€Œæœªä¾å…©æ®µå¼å·¦è½‰ã€ã€ã€Œä¸æš«åœè®“è¡Œäººã€ã€ ã€Œé€†å‘è¡Œé§›ã€ã€ã€Œè½‰å½æœªä¾è¦å®šã€ã€ã€Œè›‡è¡Œã€æƒ¡æ„é€¼è»Šã€ç­‰8é …ã€‚"
        st.markdown(f"<br>#### {f1.replace(prog, f':red[{prog}]')}\n#### {f2}", unsafe_allow_html=True)

        # å¯«å…¥èˆ‡å¯„ä¿¡
        file_hash = target_file.name + str(target_file.size)
        if st.session_state.get("v70_done") != file_hash:
            with st.status("ğŸš€ åŸ·è¡Œå¯«å…¥èˆ‡å¯„ä¿¡...") as s:
                gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
                sh = gc.open_by_url(GOOGLE_SHEET_URL); ws = sh.get_worksheet(0)
                
                h1_raw = ["çµ±è¨ˆæœŸé–“", title_wk, "", title_yt, "", title_ly, "", "åŒæœŸæ¯”è¼ƒ", "ç›®æ¨™å€¼", "é”æˆç‡"]
                
                clean_payload = [h1_raw]
                for r in all_rows:
                    clean_row = []
                    for cell in r:
                        if isinstance(cell, (int, float, np.integer)): clean_row.append(int(cell))
                        else: clean_row.append(str(cell))
                    clean_payload.append(clean_row)
                
                ws.update(range_name='A2', values=clean_payload)
                
                reqs = []
                for col_p in [(1,3), (3,5), (5,7)]:
                    reqs.append(get_merge_request(ws.id, col_p[0], col_p[1]))
                    reqs.append(get_center_align_request(ws.id, col_p[0], col_p[1]))
                
                for i, txt in [(2, title_wk), (4, title_yt), (6, title_ly)]:
                    reqs.append(get_header_red_req(ws.id, 2, i, txt))
                
                idx_f = 2 + len(clean_payload) + 1
                ws.update_cell(idx_f, 1, f1); ws.update_cell(idx_f+1, 1, f2)
                reqs.append(get_footer_percent_red_req(ws.id, idx_f, 1, f1))
                sh.batch_update({"requests": reqs})
                
                if "email" in st.secrets:
                    sender = st.secrets["email"]["user"]
                    receiver = st.secrets.get("email", {}).get("to", sender)
                    
                    out = io.BytesIO(); pd.DataFrame(clean_payload).to_excel(out, index=False)
                    server = smtplib.SMTP('smtp.gmail.com', 587); server.starttls()
                    server.login(sender, st.secrets["email"]["password"])
                    
                    msg = MIMEMultipart()
                    msg['From'] = sender; msg['To'] = receiver
                    msg['Subject'] = Header(f"ğŸš¦ Focus å ±è¡¨ - {e_yt_str}", "utf-8").encode()
                    msg.attach(MIMEText(f"{f1}\n{f2}", "plain"))
                    part = MIMEBase("application", "octet-stream"); part.set_payload(out.getvalue())
                    encoders.encode_base64(part); part.add_header("Content-Disposition", 'attachment; filename="Report.xlsx"')
                    msg.attach(part)
                    
                    server.send_message(msg); server.quit()
                
                st.session_state["v70_done"] = file_hash
                st.balloons(); s.update(label="å®Œæˆ", state="complete")

    except Exception as e:
        st.error(f"éŒ¯èª¤: {e}")
        st.code(traceback.format_exc())
