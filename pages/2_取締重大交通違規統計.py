import streamlit as st
import pandas as pd
import re
import io
import smtplib
import gspread
import calendar
import pypdf
import numpy as np
import traceback
from datetime import date
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from email.header import Header

# --- åˆå§‹åŒ–é…ç½® ---
st.set_page_config(page_title="é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ", layout="wide", page_icon="ğŸš¦")
st.title("ğŸš¦ é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ (v69 Email ä¿®å¾©ç‰ˆ)")

# ==========================================
# 0. è¨­å®šå€
# ==========================================
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1HaFu5PZkFDUg7WZGV9khyQ0itdGXhXUakP4_BClFTUg/edit" 
VIOLATION_TARGETS = {'åˆè¨ˆ': 11817, 'ç§‘æŠ€åŸ·æ³•': 0, 'è–äº­æ‰€': 1200, 'é¾æ½­æ‰€': 1500, 'ä¸­èˆˆæ‰€': 1200, 'çŸ³é–€æ‰€': 1000, 'é«˜å¹³æ‰€': 800, 'ä¸‰å’Œæ‰€': 500, 'è­¦å‚™éšŠ': 0, 'äº¤é€šåˆ†éšŠ': 1000}
UNIT_MAP = {'è–äº­æ´¾å‡ºæ‰€': 'è–äº­æ‰€', 'é¾æ½­æ´¾å‡ºæ‰€': 'é¾æ½­æ‰€', 'ä¸­èˆˆæ´¾å‡ºæ‰€': 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ´¾å‡ºæ‰€': 'çŸ³é–€æ‰€', 'é«˜å¹³æ´¾å‡ºæ‰€': 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ´¾å‡ºæ‰€': 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ': 'è­¦å‚™éšŠ', 'é¾æ½­äº¤é€šåˆ†éšŠ': 'äº¤é€šåˆ†éšŠ', 'ç§‘æŠ€åŸ·æ³•': 'ç§‘æŠ€åŸ·æ³•'}
UNIT_ORDER = ['ç§‘æŠ€åŸ·æ³•', 'è–äº­æ‰€', 'é¾æ½­æ‰€', 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ‰€', 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ', 'äº¤é€šåˆ†éšŠ']

# ==========================================
# 1. Google è©¦ç®—è¡¨æ ¼å¼æŒ‡ä»¤
# ==========================================
def get_merge_request(ws_id, start_col, end_col):
    return {"mergeCells": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "mergeType": "MERGE_ALL"}}

def get_center_align_request(ws_id, start_col, end_col):
    return {"repeatCell": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "cell": {"userEnteredFormat": {"horizontalAlignment": "CENTER"}}, "fields": "userEnteredFormat.horizontalAlignment"}}

def get_header_red_req(ws_id, row_idx, col_idx, text):
    red_chars = set("0123456789~().%")
    runs = []
    text_str = str(text)
    last_is_red = None
    for i, char in enumerate(text_str):
        is_red = char in red_chars
        if is_red != last_is_red:
            color = {"red": 1.0, "green": 0, "blue": 0} if is_red else {"red": 0, "green": 0, "blue": 0}
            runs.append({"startIndex": i, "format": {"foregroundColor": color, "bold": is_red}})
            last_is_red = is_red
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text_str}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

def get_footer_percent_red_req(ws_id, row_idx, col_idx, text):
    runs = [{"startIndex": 0, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}}]
    text_str = str(text)
    match = re.search(r'(\d+\.?\d*%)', text_str)
    if match:
        start, end = match.start(), match.end()
        runs.append({"startIndex": start, "format": {"foregroundColor": {"red": 1.0, "green": 0, "blue": 0}, "bold": True}})
        if end < len(text_str): runs.append({"startIndex": end, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}})
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text_str}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

# ==========================================
# 2. æ ¸å¿ƒè§£æå¼•æ“
# ==========================================
def clean_int(val):
    try:
        if pd.isna(val) or str(val).strip() in ['â€”', '', '-', 'nan']: return 0
        s = str(val).replace(',', '').strip()
        return int(float(s))
    except: return 0

def extract_single_report_data(file_obj):
    counts = {}
    date_str = "0000~0000"
    
    try:
        # ä¾æª”ååˆ¤æ–·é¡å‹
        is_pdf = file_obj.name.lower().endswith('.pdf')
        # æœ‰äº› PDF è¢«å­˜æˆ CSVï¼Œé€éå˜—è©¦è®€å–ä¾†åˆ¤æ–·
        if file_obj.name.lower().endswith('.csv'):
            try:
                # è©¦è®€å‰å¹¾å€‹ byte çœ‹æ˜¯ä¸æ˜¯ PDF Header
                file_obj.seek(0)
                if b'%PDF' in file_obj.read(10): is_pdf = True
                file_obj.seek(0)
            except: pass

        if is_pdf:
            reader = pypdf.PdfReader(file_obj)
            text = ""
            for page in reader.pages: text += page.extract_text() + "\n"
            
            m = re.search(r'(\d{3,7}).*è‡³\s*(\d{3,7})', text)
            if m: date_str = f"{m.group(1)}~{m.group(2)}"
            
            clean_text = text.replace(')', ' ').replace('(', ' ').replace('%', ' ').replace('\n', ' ')
            for unit in UNIT_ORDER + ['åˆè¨ˆ']:
                try:
                    start = clean_text.find(unit)
                    if start != -1:
                        sub = clean_text[start+len(unit):start+150]
                        tokens = [t.replace(',','') for t in sub.split() if t.replace(',','').replace('-','',1).isdigit()]
                        if len(tokens) >= 3: counts[unit] = [clean_int(tokens[1]), clean_int(tokens[2])]
                        elif len(tokens) >= 2: counts[unit] = [clean_int(tokens[0]), clean_int(tokens[1])]
                except: continue
        else:
            # Excel / CSV
            try: df = pd.read_excel(file_obj, header=None)
            except: 
                file_obj.seek(0)
                try: df = pd.read_csv(file_obj, header=None, encoding='utf-8', on_bad_lines='skip')
                except: 
                    file_obj.seek(0)
                    df = pd.read_csv(file_obj, header=None, encoding='big5', on_bad_lines='skip')

            top_txt = df.iloc[:15].astype(str).to_string()
            m = re.search(r'(\d{3,7}).*è‡³\s*(\d{3,7})', top_txt)
            if m: date_str = f"{m.group(1)}~{m.group(2)}"
            
            idx_int, idx_rem = 1, 2
            for r in range(min(30, len(df))):
                row_vals = df.iloc[r].astype(str).tolist()
                for c, val in enumerate(row_vals):
                    v = val.replace('\n', '').replace(' ', '')
                    if "æ””åœ" in v: idx_int = c
                    if "é€•è¡Œ" in v: idx_rem = c
            
            active_unit = None
            for _, row in df.iterrows():
                row_s = " ".join(row.astype(str))
                # æ’é™¤è¶…è¼‰
                if "è¶…è¼‰" in row_s: continue
                
                if "åˆè¨ˆ" in str(row[0]) or "ç¸½è¨ˆ" in str(row[0]): active_unit = "åˆè¨ˆ"
                elif "ç§‘æŠ€åŸ·æ³•" in str(row[0]): active_unit = "ç§‘æŠ€åŸ·æ³•"
                else:
                    for full, short in UNIT_MAP.items():
                        if short in str(row[0]): active_unit = short; break
                
                if active_unit:
                    try:
                        counts[active_unit] = [clean_int(row[idx_int]), clean_int(row[idx_rem])]
                    except: pass
                    active_unit = None

    except Exception as e: print(f"è§£æéŒ¯èª¤: {e}")
        
    return counts, date_str

# ==========================================
# 3. ç•«é¢é¡¯ç¤ºèˆ‡è‡ªå‹•åŒ–
# ==========================================
files = st.file_uploader("è«‹ä¸Šå‚³ 3 å€‹ Focus å ±è¡¨", accept_multiple_files=True)

if files and len(files) >= 3:
    try:
        parsed_results = []
        for f in files:
            d, date_rng = extract_single_report_data(f)
            parsed_results.append({"file": f, "data": d, "date": date_rng})
        
        f_wk, f_yt, f_ly = None, None, None
        for item in parsed_results:
            nm = item['file'].name
            if "(1)" in nm: f_yt = item
            elif "(2)" in nm: f_ly = item
            else: f_wk = item
        
        if not f_yt: f_yt = parsed_results[1]
        if not f_ly: f_ly = parsed_results[2]
        if not f_wk: f_wk = parsed_results[0]

        d_wk, title_wk = f_wk['data'], f"æœ¬æœŸ({f_wk['date']})"
        d_yt, title_yt = f_yt['data'], f"æœ¬å¹´ç´¯è¨ˆ({f_yt['date']})"
        d_ly, title_ly = f_ly['data'], f"å»å¹´ç´¯è¨ˆ({f_ly['date']})"

        def red_h(t): return "".join([f"<span style='color:red; font-weight:bold;'>{c}</span>" if c in "0123456789~().%" else c for c in t])
        
        html_header = f"""
        <thead>
            <tr>
                <th>çµ±è¨ˆæœŸé–“</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_wk)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_yt)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_ly)}</th>
                <th>åŒæœŸæ¯”è¼ƒ</th>
                <th>ç›®æ¨™å€¼</th>
                <th>é”æˆç‡</th>
            </tr>
        </thead>
        """

        rows = []
        for u in UNIT_ORDER:
            wk = d_wk.get(u, [0, 0]); yt = d_yt.get(u, [0, 0]); ly = d_ly.get(u, [0, 0])
            yt_tot = sum(yt); ly_tot = sum(ly); target = VIOLATION_TARGETS.get(u, 0)
            rows.append([u, wk[0], wk[1], yt[0], yt[1], ly[0], ly[1], yt_tot - ly_tot, target, f"{yt_tot/target:.0%}" if target > 0 else "â€”"])
        
        sum_wk0 = sum(r[1] for r in rows); sum_wk1 = sum(r[2] for r in rows)
        sum_yt0 = sum(r[3] for r in rows); sum_yt1 = sum(r[4] for r in rows)
        sum_ly0 = sum(r[5] for r in rows); sum_ly1 = sum(r[6] for r in rows)
        sum_diff = (sum_yt0 + sum_yt1) - (sum_ly0 + sum_ly1)
        total_target = VIOLATION_TARGETS.get('åˆè¨ˆ', 11817)
        total_acc = f"{(sum_yt0+sum_yt1)/total_target:.0%}" if total_target > 0 else "0%"
        
        total_row = ["åˆè¨ˆ", sum_wk0, sum_wk1, sum_yt0, sum_yt1, sum_ly0, sum_ly1, sum_diff, total_target, total_acc]
        method_row = ["å–ç· æ–¹å¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "", "", ""]
        all_rows = [method_row, total_row] + rows
        
        st.success("âœ… è§£ææˆåŠŸï¼æ¨™é ­èˆ‡æ•¸æ“šå·²å°±ç·’ã€‚")
        table_body = "".join([f"<tr>{''.join([f'<td>{x}</td>' for x in r])}</tr>" for r in all_rows])
        st.write(f"<table style='text-align:center; width:100%; border-collapse:collapse;' border='1'>{html_header}<tbody>{table_body}</tbody></table>", unsafe_allow_html=True)

        try:
            curr_year = date.today().year
            d_str = f_yt['date'].split('~')[1]
            mon = int(d_str[:2]); day = int(d_str[2:])
            prog = f"{((date(curr_year, mon, day) - date(curr_year, 1, 1)).days + 1) / (366 if calendar.isleap(curr_year) else 365):.1%}"
            e_yt_str = f"{curr_year-1911}å¹´{mon}æœˆ{day}æ—¥"
        except: prog = "98.0%"; e_yt_str = "114å¹´12æœˆXXæ—¥"

        f1 = f"ä¸€ã€æœ¬æœŸå®šç¾©ï¼šä¿‚æŒ‡è©²æœŸæ˜±é€šç³»çµ±å…¥æ¡ˆä»¶æ•¸ï¼›ä»¥å¹´åº•é”æˆç‡100%ç‚ºåŸºæº–ï¼Œçµ±è¨ˆæˆªè‡³ {e_yt_str} (å…¥æ¡ˆæ—¥æœŸ)æ‡‰é”æˆç‡ç‚º{prog}ã€‚"
        f2 = "äºŒã€é‡å¤§äº¤é€šé•è¦æŒ‡ï¼šã€Œé—–ç´…ç‡ˆã€ã€ã€Œé…’å¾Œé§•è»Šã€ã€ã€Œåš´é‡è¶…é€Ÿã€ã€ã€Œæœªä¾å…©æ®µå¼å·¦è½‰ã€ã€ã€Œä¸æš«åœè®“è¡Œäººã€ã€ ã€Œé€†å‘è¡Œé§›ã€ã€ã€Œè½‰å½æœªä¾è¦å®šã€ã€ã€Œè›‡è¡Œã€æƒ¡æ„é€¼è»Šã€ç­‰8é …ã€‚"
        st.markdown(f"<br>#### {f1.replace(prog, f':red[{prog}]')}\n#### {f2}", unsafe_allow_html=True)

        file_hash = "".join([f.name + str(f.size) for f in files])
        if st.session_state.get("v69_done") != file_hash:
            with st.status("ğŸš€ åŸ·è¡Œé›²ç«¯å¯«å…¥èˆ‡å¯„ä¿¡...") as s:
                gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
                sh = gc.open_by_url(GOOGLE_SHEET_URL); ws = sh.get_worksheet(0)
                
                h1_raw = ["çµ±è¨ˆæœŸé–“", title_wk, "", title_yt, "", title_ly, "", "åŒæœŸæ¯”è¼ƒ", "ç›®æ¨™å€¼", "é”æˆç‡"]
                
                # æ•¸æ“šæ¸…æ´—ï¼šå¼·åˆ¶è½‰å‹
                clean_payload = [h1_raw]
                for r in all_rows:
                    clean_row = []
                    for cell in r:
                        if isinstance(cell, (int, float, np.integer, np.floating)): clean_row.append(int(cell))
                        else: clean_row.append(str(cell))
                    clean_payload.append(clean_row)
                
                ws.update(range_name='A2', values=clean_payload)
                
                reqs = []
                for col_p in [(1,3), (3,5), (5,7)]:
                    reqs.append(get_merge_request(ws.id, col_p[0], col_p[1]))
                    reqs.append(get_center_align_request(ws.id, col_p[0], col_p[1]))
                
                for i, txt in [(2, title_wk), (4, title_yt), (6, title_ly)]:
                    reqs.append(get_header_red_req(ws.id, 2, i, txt))
                
                idx_f = 2 + len(clean_payload) + 1
                ws.update_cell(idx_f, 1, f1); ws.update_cell(idx_f+1, 1, f2)
                reqs.append(get_footer_percent_red_req(ws.id, idx_f, 1, f1))
                
                sh.batch_update({"requests": reqs})
                
                # --- EMAIL ä¿®å¾©éƒ¨åˆ† ---
                if "email" in st.secrets:
                    sender_email = st.secrets["email"]["user"]
                    # å˜—è©¦å¾ secrets è®€å– 'to'ï¼Œè‹¥ç„¡å‰‡å¯„çµ¦è‡ªå·±
                    receiver_email = st.secrets.get("email", {}).get("to", sender_email)
                    
                    out = io.BytesIO(); pd.DataFrame(clean_payload).to_excel(out, index=False)
                    server = smtplib.SMTP('smtp.gmail.com', 587); server.starttls()
                    server.login(sender_email, st.secrets["email"]["password"])
                    
                    msg = MIMEMultipart()
                    msg['From'] = sender_email
                    msg['To'] = receiver_email  # â˜…â˜…â˜… é—œéµä¿®æ­£ï¼šåŠ å…¥ To æ¨™é ­
                    msg['Subject'] = Header(f"ğŸš¦ Focus å ±è¡¨ - {e_yt_str}", "utf-8").encode()
                    
                    msg.attach(MIMEText(f"{f1}\n{f2}", "plain"))
                    part = MIMEBase("application", "octet-stream"); part.set_payload(out.getvalue())
                    encoders.encode_base64(part); part.add_header("Content-Disposition", 'attachment; filename="Report.xlsx"')
                    msg.attach(part)
                    
                    server.send_message(msg); server.quit()
                
                st.session_state["v69_done"] = file_hash
                st.balloons(); s.update(label="å…¨éƒ¨å®Œæˆ", state="complete")
    
    except Exception as e:
        st.error(f"éŒ¯èª¤: {str(e)}")
        with st.expander("æŸ¥çœ‹éŒ¯èª¤è©³æƒ…"): st.code(traceback.format_exc())
