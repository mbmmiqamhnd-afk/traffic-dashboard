import streamlit as st
import pandas as pd
import re
import io
import smtplib
import gspread
import calendar
import pypdf
import numpy as np
import traceback
import csv
from datetime import date
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
from email.header import Header

# --- åˆå§‹åŒ–é…ç½® ---
st.set_page_config(page_title="é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ", layout="wide", page_icon="ğŸš¦")
st.title("ğŸš¦ é‡å¤§äº¤é€šé•è¦çµ±è¨ˆ (v73 åº§æ¨™é–å®šç‰ˆ)")

# ==========================================
# 0. è¨­å®šå€
# ==========================================
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/1HaFu5PZkFDUg7WZGV9khyQ0itdGXhXUakP4_BClFTUg/edit" 
VIOLATION_TARGETS = {'åˆè¨ˆ': 11817, 'ç§‘æŠ€åŸ·æ³•': 0, 'è–äº­æ‰€': 1200, 'é¾æ½­æ‰€': 1500, 'ä¸­èˆˆæ‰€': 1200, 'çŸ³é–€æ‰€': 1000, 'é«˜å¹³æ‰€': 800, 'ä¸‰å’Œæ‰€': 500, 'è­¦å‚™éšŠ': 0, 'äº¤é€šåˆ†éšŠ': 1000}

# å–®ä½å°ç…§è¡¨
UNIT_MAP = {
    'è–äº­æ´¾å‡ºæ‰€': 'è–äº­æ‰€', 'é¾æ½­æ´¾å‡ºæ‰€': 'é¾æ½­æ‰€', 'ä¸­èˆˆæ´¾å‡ºæ‰€': 'ä¸­èˆˆæ‰€', 
    'çŸ³é–€æ´¾å‡ºæ‰€': 'çŸ³é–€æ‰€', 'é«˜å¹³æ´¾å‡ºæ‰€': 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ´¾å‡ºæ‰€': 'ä¸‰å’Œæ‰€', 
    'è­¦å‚™éšŠ': 'è­¦å‚™éšŠ', 'é¾æ½­äº¤é€šåˆ†éšŠ': 'äº¤é€šåˆ†éšŠ', 'äº¤é€šä¸­éšŠ': 'äº¤é€šåˆ†éšŠ',
    'ç§‘æŠ€åŸ·æ³•': 'ç§‘æŠ€åŸ·æ³•', 'äº¤é€šçµ„': 'ç§‘æŠ€åŸ·æ³•'
}

UNIT_ORDER = ['ç§‘æŠ€åŸ·æ³•', 'è–äº­æ‰€', 'é¾æ½­æ‰€', 'ä¸­èˆˆæ‰€', 'çŸ³é–€æ‰€', 'é«˜å¹³æ‰€', 'ä¸‰å’Œæ‰€', 'è­¦å‚™éšŠ', 'äº¤é€šåˆ†éšŠ']

# ==========================================
# 1. Google è©¦ç®—è¡¨æ ¼å¼æŒ‡ä»¤
# ==========================================
def get_merge_request(ws_id, start_col, end_col):
    return {"mergeCells": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "mergeType": "MERGE_ALL"}}

def get_center_align_request(ws_id, start_col, end_col):
    return {"repeatCell": {"range": {"sheetId": ws_id, "startRowIndex": 1, "endRowIndex": 2, "startColumnIndex": start_col, "endColumnIndex": end_col}, "cell": {"userEnteredFormat": {"horizontalAlignment": "CENTER"}}, "fields": "userEnteredFormat.horizontalAlignment"}}

def get_header_red_req(ws_id, row_idx, col_idx, text):
    red_chars = set("0123456789~().%")
    runs = []
    text_str = str(text)
    last_is_red = None
    for i, char in enumerate(text_str):
        is_red = char in red_chars
        if is_red != last_is_red:
            color = {"red": 1.0, "green": 0, "blue": 0} if is_red else {"red": 0, "green": 0, "blue": 0}
            runs.append({"startIndex": i, "format": {"foregroundColor": color, "bold": is_red}})
            last_is_red = is_red
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text_str}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

def get_footer_percent_red_req(ws_id, row_idx, col_idx, text):
    runs = [{"startIndex": 0, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}}]
    text_str = str(text)
    match = re.search(r'(\d+\.?\d*%)', text_str)
    if match:
        start, end = match.start(), match.end()
        runs.append({"startIndex": start, "format": {"foregroundColor": {"red": 1.0, "green": 0, "blue": 0}, "bold": True}})
        if end < len(text_str): runs.append({"startIndex": end, "format": {"foregroundColor": {"red": 0, "green": 0, "blue": 0}, "bold": False}})
    return {"updateCells": {"rows": [{"values": [{"userEnteredValue": {"stringValue": text_str}, "textFormatRuns": runs}]}], "fields": "userEnteredValue,textFormatRuns", "range": {"sheetId": ws_id, "startRowIndex": row_idx-1, "endRowIndex": row_idx, "startColumnIndex": col_idx-1, "endColumnIndex": col_idx}}}

# ==========================================
# 2. æ ¸å¿ƒè§£æå¼•æ“ (Focus CSV å°ˆç”¨)
# ==========================================
def clean_int(val):
    try:
        if pd.isna(val) or str(val).strip() in ['â€”', '', '-', 'nan', 'NaN']: return 0
        s = str(val).replace(',', '').strip()
        return int(float(s))
    except: return 0

def extract_focus_csv_data(file_obj):
    counts = {}
    date_str = "0000~0000"
    
    try:
        file_obj.seek(0)
        # å˜—è©¦è®€å– CSV
        try: df = pd.read_csv(file_obj, header=None, encoding='utf-8', on_bad_lines='skip')
        except: 
            file_obj.seek(0)
            df = pd.read_csv(file_obj, header=None, encoding='big5', on_bad_lines='skip')
        
        # 1. æŠ“å–æ—¥æœŸ (å¾ Row 4: "å…¥æ¡ˆæ—¥æœŸï¼š1141223 è‡³ 1141229")
        # æƒæå‰ 10 è¡Œå°‹æ‰¾æ—¥æœŸ
        top_txt = df.iloc[:10].astype(str).to_string()
        m = re.search(r'å…¥æ¡ˆæ—¥æœŸï¼š(\d+)\s*è‡³\s*(\d+)', top_txt)
        if m: 
            s_d, e_d = m.group(1), m.group(2)
            date_str = f"{s_d[-4:]}~{e_d[-4:]}" # å–å¾Œ4ç¢¼ MMDD

        # 2. å®šä½ã€Œåˆè¨ˆã€æ¬„ä½
        # æ ¹æ“šåˆ†æï¼ŒRow 5 (index 5) åŒ…å« "åˆè¨ˆ"
        # æˆ‘å€‘æœå°‹åŒ…å« "å–®ä½" çš„é‚£ä¸€è¡Œä½œç‚º Header Row
        header_idx = -1
        for idx, row in df.iterrows():
            if "å–®ä½" in str(row.values) and "åˆè¨ˆ" in str(row.values):
                header_idx = idx
                break
        
        if header_idx != -1:
            # åœ¨ Header Row å°‹æ‰¾ "åˆè¨ˆ" çš„ç´¢å¼•
            row_vals = df.iloc[header_idx].tolist()
            # æ‰¾æœ€å¾Œä¸€å€‹ "åˆè¨ˆ" (é€šå¸¸åœ¨æœ€å³é‚Š)
            total_indices = [i for i, x in enumerate(row_vals) if "åˆè¨ˆ" in str(x)]
            if total_indices:
                col_total_int = total_indices[-1] # åˆè¨ˆæ¬„ä½ (å°æ‡‰ä¸‹ä¸€åˆ—çš„ "ç¾å ´æ””åœ")
                col_total_rem = col_total_int + 1 # åˆè¨ˆæ¬„ä½ (å°æ‡‰ä¸‹ä¸€åˆ—çš„ "é€•è¡Œèˆ‰ç™¼")

                # 3. æŠ“å–æ•¸æ“š (å¾ Header Row + 2 é–‹å§‹)
                for r_idx in range(header_idx + 2, len(df)):
                    row = df.iloc[r_idx]
                    raw_unit = str(row[2]).strip() # å–®ä½é€šå¸¸åœ¨ç¬¬ 2 æ¬„ (index 2), è¦– CSV è€Œå®š
                    # æ ¹æ“š Snippet: å–®ä½åœ¨ col 2 (index 2)
                    
                    # é˜²å‘†: å¦‚æœ col 2 ä¸æ˜¯å–®ä½ï¼Œå˜—è©¦ col 0, 1
                    target_unit = None
                    # æª¢æŸ¥ raw_unit æ˜¯å¦åœ¨ map ä¸­
                    for full, short in UNIT_MAP.items():
                        if short in raw_unit: 
                            target_unit = short
                            break
                    if not target_unit:
                         # å˜—è©¦ col 0, 1, 3
                         for c in [0, 1, 3]:
                             if c < len(row):
                                 val = str(row[c]).strip()
                                 for full, short in UNIT_MAP.items():
                                     if short in val: target_unit = short; break
                                 if target_unit: break
                    
                    if target_unit:
                        v_int = clean_int(row[col_total_int])
                        v_rem = clean_int(row[col_total_rem])
                        counts[target_unit] = [v_int, v_rem]

    except Exception as e:
        print(f"è§£æéŒ¯èª¤ {file_obj.name}: {e}")
        
    return counts, date_str

# ==========================================
# 3. ç•«é¢é¡¯ç¤ºèˆ‡è‡ªå‹•åŒ–
# ==========================================
files = st.file_uploader("è«‹ä¸Šå‚³ 3 å€‹ Focus å ±è¡¨ (focus114.csv)", accept_multiple_files=True)

if files and len(files) >= 3:
    try:
        # 1. è§£æ
        parsed_results = []
        for f in files:
            d, date_rng = extract_focus_csv_data(f)
            parsed_results.append({"file": f, "data": d, "date": date_rng})
        
        # 2. æ’åº (ä¾æª”å)
        f_wk, f_yt, f_ly = None, None, None
        for item in parsed_results:
            nm = item['file'].name
            if "(2)" in nm: f_ly = item     # (2) é€šå¸¸æ˜¯å»å¹´
            elif "(1)" in nm: f_yt = item   # (1) é€šå¸¸æ˜¯æœ¬å¹´
            else: f_wk = item               # ç„¡æ‹¬è™Ÿæ˜¯æœ¬æœŸ
        
        # é˜²å‘†æ’åº
        if not f_yt: f_yt = parsed_results[1]
        if not f_ly: f_ly = parsed_results[2]
        if not f_wk: f_wk = parsed_results[0]

        d_wk, title_wk = f_wk['data'], f"æœ¬æœŸ({f_wk['date']})"
        d_yt, title_yt = f_yt['data'], f"æœ¬å¹´ç´¯è¨ˆ({f_yt['date']})"
        d_ly, title_ly = f_ly['data'], f"å»å¹´ç´¯è¨ˆ({f_ly['date']})"

        # HTML Header
        def red_h(t): return "".join([f"<span style='color:red; font-weight:bold;'>{c}</span>" if c in "0123456789~().%" else c for c in t])
        html_header = f"""
        <thead>
            <tr>
                <th>çµ±è¨ˆæœŸé–“</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_wk)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_yt)}</th>
                <th colspan='2' style='text-align:center;'>{red_h(title_ly)}</th>
                <th>åŒæœŸæ¯”è¼ƒ</th>
                <th>ç›®æ¨™å€¼</th>
                <th>é”æˆç‡</th>
            </tr>
        </thead>
        """

        # 3. æ•¸æ“šçµ„è£
        rows = []
        for u in UNIT_ORDER:
            wk = d_wk.get(u, [0, 0]); yt = d_yt.get(u, [0, 0]); ly = d_ly.get(u, [0, 0])
            yt_tot = sum(yt); ly_tot = sum(ly); target = VIOLATION_TARGETS.get(u, 0)
            rows.append([u, wk[0], wk[1], yt[0], yt[1], ly[0], ly[1], yt_tot - ly_tot, target, f"{yt_tot/target:.0%}" if target > 0 else "â€”"])
        
        # åˆè¨ˆåˆ—
        sum_wk0 = sum(r[1] for r in rows); sum_wk1 = sum(r[2] for r in rows)
        sum_yt0 = sum(r[3] for r in rows); sum_yt1 = sum(r[4] for r in rows)
        sum_ly0 = sum(r[5] for r in rows); sum_ly1 = sum(r[6] for r in rows)
        sum_diff = (sum_yt0 + sum_yt1) - (sum_ly0 + sum_ly1)
        total_target = VIOLATION_TARGETS.get('åˆè¨ˆ', 11817)
        total_acc = f"{(sum_yt0+sum_yt1)/total_target:.0%}" if total_target > 0 else "0%"
        
        total_row = ["åˆè¨ˆ", sum_wk0, sum_wk1, sum_yt0, sum_yt1, sum_ly0, sum_ly1, sum_diff, total_target, total_acc]
        method_row = ["å–ç· æ–¹å¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "ç¾å ´æ””åœ", "é€•è¡Œèˆ‰ç™¼", "", "", ""]
        all_rows = [method_row, total_row] + rows
        
        st.success("âœ… Focus å ±è¡¨è§£æå®Œæˆï¼")
        
        # é¡¯ç¤º
        table_body = "".join([f"<tr>{''.join([f'<td>{x}</td>' for x in r])}</tr>" for r in all_rows])
        st.write(f"<table style='text-align:center; width:100%; border-collapse:collapse;' border='1'>{html_header}<tbody>{table_body}</tbody></table>", unsafe_allow_html=True)

        # èªªæ˜
        try:
            curr_year = date.today().year
            d_str = f_yt['date'].split('~')[1]
            mon = int(d_str[:2]); day = int(d_str[2:])
            prog = f"{((date(curr_year, mon, day) - date(curr_year, 1, 1)).days + 1) / (366 if calendar.isleap(curr_year) else 365):.1%}"
            e_yt_str = f"{curr_year-1911}å¹´{mon}æœˆ{day}æ—¥"
        except: prog = "98.0%"; e_yt_str = "114å¹´12æœˆXXæ—¥"

        f1 = f"ä¸€ã€æœ¬æœŸå®šç¾©ï¼šä¿‚æŒ‡è©²æœŸæ˜±é€šç³»çµ±å…¥æ¡ˆä»¶æ•¸ï¼›ä»¥å¹´åº•é”æˆç‡100%ç‚ºåŸºæº–ï¼Œçµ±è¨ˆæˆªè‡³ {e_yt_str} (å…¥æ¡ˆæ—¥æœŸ)æ‡‰é”æˆç‡ç‚º{prog}ã€‚"
        f2 = "äºŒã€é‡å¤§äº¤é€šé•è¦æŒ‡ï¼šã€Œé—–ç´…ç‡ˆã€ã€ã€Œé…’å¾Œé§•è»Šã€ã€ã€Œåš´é‡è¶…é€Ÿã€ã€ã€Œæœªä¾å…©æ®µå¼å·¦è½‰ã€ã€ã€Œä¸æš«åœè®“è¡Œäººã€ã€ ã€Œé€†å‘è¡Œé§›ã€ã€ã€Œè½‰å½æœªä¾è¦å®šã€ã€ã€Œè›‡è¡Œã€æƒ¡æ„é€¼è»Šã€ç­‰8é …ã€‚"
        st.markdown(f"<br>#### {f1.replace(prog, f':red[{prog}]')}\n#### {f2}", unsafe_allow_html=True)

        # å¯«å…¥ & å¯„ä¿¡
        file_hash = "".join([f.name + str(f.size) for f in files])
        if st.session_state.get("v73_done") != file_hash:
            with st.status("ğŸš€ å¯«å…¥ Google Sheets...") as s:
                gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
                sh = gc.open_by_url(GOOGLE_SHEET_URL); ws = sh.get_worksheet(0)
                
                h1_raw = ["çµ±è¨ˆæœŸé–“", title_wk, "", title_yt, "", title_ly, "", "åŒæœŸæ¯”è¼ƒ", "ç›®æ¨™å€¼", "é”æˆç‡"]
                # å¼·åˆ¶æ¸…æ´—
                clean_payload = [h1_raw]
                for r in all_rows:
                    clean_row = []
                    for cell in r:
                        if isinstance(cell, (int, float, np.integer)): clean_row.append(int(cell))
                        else: clean_row.append(str(cell))
                    clean_payload.append(clean_row)
                
                ws.update(range_name='A2', values=clean_payload)
                
                reqs = []
                for col_p in [(1,3), (3,5), (5,7)]:
                    reqs.append(get_merge_request(ws.id, col_p[0], col_p[1]))
                    reqs.append(get_center_align_request(ws.id, col_p[0], col_p[1]))
                for i, txt in [(2, title_wk), (4, title_yt), (6, title_ly)]:
                    reqs.append(get_header_red_req(ws.id, 2, i, txt))
                idx_f = 2 + len(clean_payload) + 1
                ws.update_cell(idx_f, 1, f1); ws.update_cell(idx_f+1, 1, f2)
                reqs.append(get_footer_percent_red_req(ws.id, idx_f, 1, f1))
                sh.batch_update({"requests": reqs})
                
                if "email" in st.secrets:
                    sender = st.secrets["email"]["user"]
                    receiver = st.secrets.get("email", {}).get("to", sender)
                    out = io.BytesIO(); pd.DataFrame(clean_payload).to_excel(out, index=False)
                    server = smtplib.SMTP('smtp.gmail.com', 587); server.starttls()
                    server.login(sender, st.secrets["email"]["password"])
                    msg = MIMEMultipart(); msg['From'] = sender; msg['To'] = receiver
                    msg['Subject'] = Header(f"ğŸš¦ Focus å ±è¡¨ - {e_yt_str}", "utf-8").encode()
                    msg.attach(MIMEText(f"{f1}\n{f2}", "plain"))
                    part = MIMEBase("application", "octet-stream"); part.set_payload(out.getvalue())
                    encoders.encode_base64(part); part.add_header("Content-Disposition", 'attachment; filename="Report.xlsx"')
                    msg.attach(part); server.send_message(msg); server.quit()
                
                st.session_state["v73_done"] = file_hash
                st.balloons(); s.update(label="å®Œæˆ", state="complete")

    except Exception as e:
        st.error(f"éŒ¯èª¤: {e}")
        st.code(traceback.format_exc())
